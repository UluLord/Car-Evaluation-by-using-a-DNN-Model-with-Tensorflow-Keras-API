{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Project] [DNN] Car_Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1R98ny36w5pC",
        "EbEApLuQCNuu",
        "Od9j-3_XEyi7"
      ],
      "authorship_tag": "ABX9TyNubF/FdGz2jah1NspREylm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Fu7pAVPsrks"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from warnings import filterwarnings\n",
        "filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Understanding"
      ],
      "metadata": {
        "id": "O6_PITrZ4crS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_data = \"/content/car.data\"                   #The data has been downloaded from https://archive.ics.uci.edu/ml/datasets/Car+Evaluation\n",
        "columns = [\"Buying\", \"Maint\", \"Doors\", \"Persons\", \"Lug_boot\", \"Safety\", \"Car\"]\n",
        "\n",
        "data_car = pd.read_csv(path_data, names = columns)\n",
        "data_car.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTqvUYEStIwx",
        "outputId": "eb988d02-8b96-49d5-80e9-16cbac1df838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Buying  Maint Doors Persons Lug_boot Safety    Car\n",
              "0  vhigh  vhigh     2       2    small    low  unacc\n",
              "1  vhigh  vhigh     2       2    small    med  unacc\n",
              "2  vhigh  vhigh     2       2    small   high  unacc\n",
              "3  vhigh  vhigh     2       2      med    low  unacc\n",
              "4  vhigh  vhigh     2       2      med    med  unacc"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48091d8b-c980-436e-bd05-0cf60f1d0d0c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Buying</th>\n",
              "      <th>Maint</th>\n",
              "      <th>Doors</th>\n",
              "      <th>Persons</th>\n",
              "      <th>Lug_boot</th>\n",
              "      <th>Safety</th>\n",
              "      <th>Car</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>small</td>\n",
              "      <td>low</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>small</td>\n",
              "      <td>med</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>small</td>\n",
              "      <td>high</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>med</td>\n",
              "      <td>low</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>med</td>\n",
              "      <td>med</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48091d8b-c980-436e-bd05-0cf60f1d0d0c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48091d8b-c980-436e-bd05-0cf60f1d0d0c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48091d8b-c980-436e-bd05-0cf60f1d0d0c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Car Evaluation Database contains examples with the structural information removed, i.e., directly relates CAR to the six input attributes: Buying, Maint, Doors, Persons, Lug_boot, Safety. Details are explained below"
      ],
      "metadata": {
        "id": "mX9pBeyd1gR8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. CAR : car acceptability (unacc, acc, good, v-good)\n",
        "\n",
        "2. PRICE    : overall price\n",
        "   * Buying    : buying price (v-high, high, med, low)\n",
        "   * Maint     : price of the maintenance (v-high, high, med, low)\n",
        "\n",
        "3. TECH     : technical characteristics\n",
        "   * COMFORT   : comfort\n",
        "   ** Doors    : number of doors (2, 3, 4, 5-more)\n",
        "   ** Persons  : capacity in terms of persons to carry (2, 4, more)\n",
        "   ** Lug_boot : the size of luggage boot (small, med, big)\n",
        "   * SAFETY    : estimated safety of the car (low, med, high)"
      ],
      "metadata": {
        "id": "0ll3GWXJzzig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_car.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyKtg4eZtXCH",
        "outputId": "77fbb131-7ac2-4c2f-b288-b6215539b04a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1728, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of Instances: 1728\n",
        "   (instances completely cover the attribute space)"
      ],
      "metadata": {
        "id": "bHCLOkzmzkh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "\n",
        "for train_indices, test_indices in sss.split(data_car, data_car[\"Buying\"]):\n",
        "  train_data = data_car.iloc[train_indices]\n",
        "  test_data = data_car.iloc[test_indices]\n",
        "\n",
        "\n",
        "print(\"train_data.shape: \", train_data.shape)\n",
        "print(\"test_data.shape: \", test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBV2CIyE4krW",
        "outputId": "f99a557f-e363-4677-9929-3fe1a2488ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data.shape:  (1382, 7)\n",
            "test_data.shape:  (346, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have split the dataset into a train dataset and a test dataset based on \"Buying\" feature.\n",
        ">\n",
        "DNN Model will be trained on train dataset and its performance will be measured on test dataset.\n",
        ">\n",
        "The test dataset won't be touched till prediction"
      ],
      "metadata": {
        "id": "K1FsPhpkXOVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.describe().T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg6bfRWTthbG",
        "outputId": "d232cd44-b6d0-4412-e521-a6c1d1630a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         count unique    top freq\n",
              "Buying    1382      4    low  346\n",
              "Maint     1382      4    low  358\n",
              "Doors     1382      4      4  351\n",
              "Persons   1382      3      2  468\n",
              "Lug_boot  1382      3    med  462\n",
              "Safety    1382      3   high  465\n",
              "Car       1382      4  unacc  969"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-773a11fa-1e41-47c6-a246-173adfd8c846\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Buying</th>\n",
              "      <td>1382</td>\n",
              "      <td>4</td>\n",
              "      <td>low</td>\n",
              "      <td>346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Maint</th>\n",
              "      <td>1382</td>\n",
              "      <td>4</td>\n",
              "      <td>low</td>\n",
              "      <td>358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doors</th>\n",
              "      <td>1382</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Persons</th>\n",
              "      <td>1382</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lug_boot</th>\n",
              "      <td>1382</td>\n",
              "      <td>3</td>\n",
              "      <td>med</td>\n",
              "      <td>462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Safety</th>\n",
              "      <td>1382</td>\n",
              "      <td>3</td>\n",
              "      <td>high</td>\n",
              "      <td>465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Car</th>\n",
              "      <td>1382</td>\n",
              "      <td>4</td>\n",
              "      <td>unacc</td>\n",
              "      <td>969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-773a11fa-1e41-47c6-a246-173adfd8c846')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-773a11fa-1e41-47c6-a246-173adfd8c846 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-773a11fa-1e41-47c6-a246-173adfd8c846');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the features have categorical observations. We can see statistic distributions of the features in train dataset above like observation count, unique values, most used observations and it's frequency."
      ],
      "metadata": {
        "id": "BhR9XxREXrtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WR_oG69tzll",
        "outputId": "3a1582cb-15ab-486f-da2f-8432f5f05a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1382 entries, 1478 to 961\n",
            "Data columns (total 7 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Buying    1382 non-null   object\n",
            " 1   Maint     1382 non-null   object\n",
            " 2   Doors     1382 non-null   object\n",
            " 3   Persons   1382 non-null   object\n",
            " 4   Lug_boot  1382 non-null   object\n",
            " 5   Safety    1382 non-null   object\n",
            " 6   Car       1382 non-null   object\n",
            "dtypes: object(7)\n",
            "memory usage: 86.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train dataset has no any missing value"
      ],
      "metadata": {
        "id": "brKsljnAa2q6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the Data for Model"
      ],
      "metadata": {
        "id": "1R98ny36w5pC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the features in the dataset have categorical observations. We should do one-hot encoding. By doing so, the observations will be only either 0 or 1 (0 if No, 1 if Yes) according to columns created from the categorical observations."
      ],
      "metadata": {
        "id": "vVdpMUFi-aiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dummies(data, columns):\n",
        "\n",
        "  data = pd.get_dummies(data, columns=columns)\n",
        "  return data\n",
        "\n",
        "train_data = dummies(train_data, train_data.drop(\"Car\", axis=1).columns)\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "UeN4VaYL-ueb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "632d8b8c-2925-4106-dadf-9c2c03d5f0c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Car  Buying_high  Buying_low  Buying_med  Buying_vhigh  Maint_high  \\\n",
              "1478    acc            0           1           0             0           1   \n",
              "199   unacc            0           0           0             1           1   \n",
              "1532  unacc            0           1           0             0           0   \n",
              "1141  unacc            0           0           1             0           0   \n",
              "1123    acc            0           0           1             0           0   \n",
              "\n",
              "      Maint_low  Maint_med  Maint_vhigh  Doors_2  ...  Doors_5more  Persons_2  \\\n",
              "1478          0          0            0        0  ...            0          0   \n",
              "199           0          0            0        0  ...            1          0   \n",
              "1532          0          1            0        1  ...            0          0   \n",
              "1141          0          1            0        0  ...            0          1   \n",
              "1123          0          1            0        0  ...            0          0   \n",
              "\n",
              "      Persons_4  Persons_more  Lug_boot_big  Lug_boot_med  Lug_boot_small  \\\n",
              "1478          0             1             0             0               1   \n",
              "199           1             0             0             0               1   \n",
              "1532          0             1             0             0               1   \n",
              "1141          0             0             1             0               0   \n",
              "1123          1             0             1             0               0   \n",
              "\n",
              "      Safety_high  Safety_low  Safety_med  \n",
              "1478            1           0           0  \n",
              "199             0           0           1  \n",
              "1532            1           0           0  \n",
              "1141            0           0           1  \n",
              "1123            0           0           1  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f14bb6ad-2aef-4cbc-b95b-e145d878c290\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Car</th>\n",
              "      <th>Buying_high</th>\n",
              "      <th>Buying_low</th>\n",
              "      <th>Buying_med</th>\n",
              "      <th>Buying_vhigh</th>\n",
              "      <th>Maint_high</th>\n",
              "      <th>Maint_low</th>\n",
              "      <th>Maint_med</th>\n",
              "      <th>Maint_vhigh</th>\n",
              "      <th>Doors_2</th>\n",
              "      <th>...</th>\n",
              "      <th>Doors_5more</th>\n",
              "      <th>Persons_2</th>\n",
              "      <th>Persons_4</th>\n",
              "      <th>Persons_more</th>\n",
              "      <th>Lug_boot_big</th>\n",
              "      <th>Lug_boot_med</th>\n",
              "      <th>Lug_boot_small</th>\n",
              "      <th>Safety_high</th>\n",
              "      <th>Safety_low</th>\n",
              "      <th>Safety_med</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1478</th>\n",
              "      <td>acc</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>unacc</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1532</th>\n",
              "      <td>unacc</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1141</th>\n",
              "      <td>unacc</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1123</th>\n",
              "      <td>acc</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f14bb6ad-2aef-4cbc-b95b-e145d878c290')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f14bb6ad-2aef-4cbc-b95b-e145d878c290 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f14bb6ad-2aef-4cbc-b95b-e145d878c290');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the dataset has 22 columns."
      ],
      "metadata": {
        "id": "hs3HbwNV_nwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transforming_data(data):\n",
        "  data[\"Car\"] = [0 if i == \"unacc\" else 1 if i == \"acc\" else 2 if i == \"good\" else 3 for i in data.Car]\n",
        "  return data\n",
        "train_data = transforming_data(train_data)"
      ],
      "metadata": {
        "id": "-2Gcv1RDedWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The observations of the target variable, \"Car\", have been transformed to numeric values so that DNN Model works and predicts. We have assigned those numbers below to the categorical observations;\n",
        ">\n",
        "* 0 if \"unacc\",\n",
        "* 1 if \"acc\",\n",
        "* 2 if \"good\",\n",
        "* 3 if \"vgood\"."
      ],
      "metadata": {
        "id": "zmRxQ3w4_zVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_data.drop([\"Car\"], axis=1).values\n",
        "y = train_data[[\"Car\"]].values"
      ],
      "metadata": {
        "id": "4F4FsA_6QAti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The train dataset has been split into X data and y data.\n",
        "* X data is consisted of independent variables which DNN model take as input,\n",
        "* y data is the dependent variable which DNN Model will predict."
      ],
      "metadata": {
        "id": "H4YKeBRNBErh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,y,\n",
        "                                                  test_size=0.2,\n",
        "                                                  random_state=42)"
      ],
      "metadata": {
        "id": "wFSr6m-7Ps0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "X data has been split into X_train which DNN Model will be trained, and X_val which the Model's performance will be validated.\n",
        ">\n",
        "Similarly y data has been split into y_train and y_val."
      ],
      "metadata": {
        "id": "QggQ1NScEJsU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building DNN Model"
      ],
      "metadata": {
        "id": "EbEApLuQCNuu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's firstly start by importing some necessary libraries"
      ],
      "metadata": {
        "id": "GpcnEhmLFC2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Dropout, Activation, InputLayer\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "metadata": {
        "id": "KRlmUB_zQ1Xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Some parameters we will use later\n",
        "\n",
        "input_shape = X_train.shape[1]\n",
        "epochs = 500\n",
        "batch_size = 32\n",
        "nb_class = len(np.unique(y_train))"
      ],
      "metadata": {
        "id": "_QMlG4eYypYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. input_shape, which is the number of columns of X_train, will be used in the DNN Model as input,\n",
        "2. training iteration will be 500 times,\n",
        "3. 32 samples in every iteration will be used,\n",
        "4. number of class will be used in the DNN Model as output."
      ],
      "metadata": {
        "id": "xvo5HpwyFPc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train, nb_class)\n",
        "y_val = to_categorical(y_val, nb_class)"
      ],
      "metadata": {
        "id": "cBV_9eYL_eZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-hot encoding has been implemented to y_train and y_val."
      ],
      "metadata": {
        "id": "Vq0ovFAFHKH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def building_model(input_shape, nb_classes):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(InputLayer(input_shape=[input_shape]))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(units=128, kernel_initializer=\"normal\"))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(units=64, kernel_initializer=\"normal\"))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(units=32, kernel_initializer=\"normal\"))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(units=nb_class, activation=\"softmax\"))\n",
        "\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "\n",
        "  return model\n",
        "\n",
        "  \n",
        "model = building_model(input_shape, nb_class)"
      ],
      "metadata": {
        "id": "Uy_1085xQ1U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we have built a DNN Model by calling building_model function.\n",
        ">\n",
        "The Model;\n",
        "* Takes input_shape variable as input,\n",
        "* Uses \"normal\" as kernel_initializer, BatchNormalization to normalize, \"relu\" as activation and randomly deactive %50 of neuron networks in all dense layers, except output,\n",
        "* Gives neurons in the amount of number of class and uses \"softmax\" as activation in output layer.\n",
        ">\n",
        "Also, the model has been compiled with parameters below:\n",
        "* \"categorical_crossentropy\" as loss,\n",
        "* \"sgd\" as optimizer,\n",
        "* \"accuracy\" as evaluation metrics."
      ],
      "metadata": {
        "id": "T-s8_Q4hHcJw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model"
      ],
      "metadata": {
        "id": "Od9j-3_XEyi7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is now time to train the Model and validate its performance. We will use EarlyStoping which will stop model training if no more improvement in validation loss after every 20 epoch."
      ],
      "metadata": {
        "id": "p66k1D-cJce9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(patience=20,\n",
        "                               restore_best_weights=True,\n",
        "                               monitor=\"val_loss\")\n",
        "hist = model.fit(X_train, y_train, batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=[X_val, y_val],\n",
        "          callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "gvSTF9CW1DPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a23b17a9-c8c3-43ca-a22d-95756b139aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "35/35 [==============================] - 3s 21ms/step - loss: 1.7670 - accuracy: 0.2326 - val_loss: 1.2378 - val_accuracy: 0.7256\n",
            "Epoch 2/500\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 1.0981 - accuracy: 0.5258 - val_loss: 1.1233 - val_accuracy: 0.7256\n",
            "Epoch 3/500\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.9034 - accuracy: 0.6579 - val_loss: 1.0232 - val_accuracy: 0.7256\n",
            "Epoch 4/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.7636 - accuracy: 0.7186 - val_loss: 0.9292 - val_accuracy: 0.7256\n",
            "Epoch 5/500\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.7043 - accuracy: 0.7557 - val_loss: 0.8409 - val_accuracy: 0.7256\n",
            "Epoch 6/500\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.6663 - accuracy: 0.7475 - val_loss: 0.7595 - val_accuracy: 0.7834\n",
            "Epoch 7/500\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.5933 - accuracy: 0.7855 - val_loss: 0.7018 - val_accuracy: 0.8231\n",
            "Epoch 8/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.5961 - accuracy: 0.7783 - val_loss: 0.6467 - val_accuracy: 0.8484\n",
            "Epoch 9/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.5644 - accuracy: 0.7747 - val_loss: 0.5945 - val_accuracy: 0.8592\n",
            "Epoch 10/500\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.5554 - accuracy: 0.7864 - val_loss: 0.5529 - val_accuracy: 0.8556\n",
            "Epoch 11/500\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.5640 - accuracy: 0.7928 - val_loss: 0.5185 - val_accuracy: 0.8556\n",
            "Epoch 12/500\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.5293 - accuracy: 0.7991 - val_loss: 0.4882 - val_accuracy: 0.8592\n",
            "Epoch 13/500\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.4926 - accuracy: 0.8281 - val_loss: 0.4611 - val_accuracy: 0.8520\n",
            "Epoch 14/500\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.5126 - accuracy: 0.8090 - val_loss: 0.4414 - val_accuracy: 0.8520\n",
            "Epoch 15/500\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.4943 - accuracy: 0.8190 - val_loss: 0.4241 - val_accuracy: 0.8520\n",
            "Epoch 16/500\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.4755 - accuracy: 0.8172 - val_loss: 0.4094 - val_accuracy: 0.8628\n",
            "Epoch 17/500\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.4714 - accuracy: 0.8299 - val_loss: 0.3984 - val_accuracy: 0.8592\n",
            "Epoch 18/500\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.4675 - accuracy: 0.8262 - val_loss: 0.3844 - val_accuracy: 0.8628\n",
            "Epoch 19/500\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.4470 - accuracy: 0.8299 - val_loss: 0.3714 - val_accuracy: 0.8664\n",
            "Epoch 20/500\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.4484 - accuracy: 0.8317 - val_loss: 0.3602 - val_accuracy: 0.8664\n",
            "Epoch 21/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8308 - val_loss: 0.3496 - val_accuracy: 0.8700\n",
            "Epoch 22/500\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.8389 - val_loss: 0.3435 - val_accuracy: 0.8736\n",
            "Epoch 23/500\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.4529 - accuracy: 0.8262 - val_loss: 0.3360 - val_accuracy: 0.8809\n",
            "Epoch 24/500\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.4097 - accuracy: 0.8480 - val_loss: 0.3256 - val_accuracy: 0.8845\n",
            "Epoch 25/500\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.4012 - accuracy: 0.8471 - val_loss: 0.3209 - val_accuracy: 0.8845\n",
            "Epoch 26/500\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.8416 - val_loss: 0.3144 - val_accuracy: 0.8881\n",
            "Epoch 27/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8552 - val_loss: 0.3125 - val_accuracy: 0.8881\n",
            "Epoch 28/500\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8561 - val_loss: 0.3043 - val_accuracy: 0.8881\n",
            "Epoch 29/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8498 - val_loss: 0.3002 - val_accuracy: 0.8881\n",
            "Epoch 30/500\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.3926 - accuracy: 0.8570 - val_loss: 0.2947 - val_accuracy: 0.8881\n",
            "Epoch 31/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8552 - val_loss: 0.2924 - val_accuracy: 0.8881\n",
            "Epoch 32/500\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.3909 - accuracy: 0.8516 - val_loss: 0.2836 - val_accuracy: 0.8881\n",
            "Epoch 33/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8579 - val_loss: 0.2793 - val_accuracy: 0.8881\n",
            "Epoch 34/500\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8579 - val_loss: 0.2756 - val_accuracy: 0.8881\n",
            "Epoch 35/500\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.3685 - accuracy: 0.8588 - val_loss: 0.2745 - val_accuracy: 0.8917\n",
            "Epoch 36/500\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.3614 - accuracy: 0.8688 - val_loss: 0.2688 - val_accuracy: 0.8917\n",
            "Epoch 37/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8814 - val_loss: 0.2675 - val_accuracy: 0.8881\n",
            "Epoch 38/500\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.3510 - accuracy: 0.8643 - val_loss: 0.2650 - val_accuracy: 0.8881\n",
            "Epoch 39/500\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.3514 - accuracy: 0.8652 - val_loss: 0.2658 - val_accuracy: 0.8881\n",
            "Epoch 40/500\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.3289 - accuracy: 0.8787 - val_loss: 0.2590 - val_accuracy: 0.8881\n",
            "Epoch 41/500\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.3538 - accuracy: 0.8661 - val_loss: 0.2572 - val_accuracy: 0.8881\n",
            "Epoch 42/500\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.3189 - accuracy: 0.8805 - val_loss: 0.2565 - val_accuracy: 0.8917\n",
            "Epoch 43/500\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.3048 - accuracy: 0.8787 - val_loss: 0.2537 - val_accuracy: 0.8917\n",
            "Epoch 44/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8742 - val_loss: 0.2468 - val_accuracy: 0.8917\n",
            "Epoch 45/500\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.3289 - accuracy: 0.8688 - val_loss: 0.2458 - val_accuracy: 0.8917\n",
            "Epoch 46/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3009 - accuracy: 0.8842 - val_loss: 0.2442 - val_accuracy: 0.8917\n",
            "Epoch 47/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3219 - accuracy: 0.8905 - val_loss: 0.2481 - val_accuracy: 0.8917\n",
            "Epoch 48/500\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.3301 - accuracy: 0.8805 - val_loss: 0.2441 - val_accuracy: 0.8917\n",
            "Epoch 49/500\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.3014 - accuracy: 0.8896 - val_loss: 0.2402 - val_accuracy: 0.8917\n",
            "Epoch 50/500\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.3483 - accuracy: 0.8661 - val_loss: 0.2372 - val_accuracy: 0.8917\n",
            "Epoch 51/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3087 - accuracy: 0.8842 - val_loss: 0.2351 - val_accuracy: 0.8917\n",
            "Epoch 52/500\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.3035 - accuracy: 0.8896 - val_loss: 0.2338 - val_accuracy: 0.8953\n",
            "Epoch 53/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3075 - accuracy: 0.8805 - val_loss: 0.2343 - val_accuracy: 0.8953\n",
            "Epoch 54/500\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.3159 - accuracy: 0.8778 - val_loss: 0.2303 - val_accuracy: 0.8953\n",
            "Epoch 55/500\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8851 - val_loss: 0.2286 - val_accuracy: 0.8917\n",
            "Epoch 56/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2906 - accuracy: 0.8896 - val_loss: 0.2284 - val_accuracy: 0.8953\n",
            "Epoch 57/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2985 - accuracy: 0.8941 - val_loss: 0.2300 - val_accuracy: 0.8953\n",
            "Epoch 58/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3052 - accuracy: 0.8968 - val_loss: 0.2296 - val_accuracy: 0.8917\n",
            "Epoch 59/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2779 - accuracy: 0.8923 - val_loss: 0.2264 - val_accuracy: 0.8953\n",
            "Epoch 60/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2662 - accuracy: 0.9032 - val_loss: 0.2250 - val_accuracy: 0.8953\n",
            "Epoch 61/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.8995 - val_loss: 0.2217 - val_accuracy: 0.8953\n",
            "Epoch 62/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2909 - accuracy: 0.8968 - val_loss: 0.2209 - val_accuracy: 0.8953\n",
            "Epoch 63/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2821 - accuracy: 0.8995 - val_loss: 0.2226 - val_accuracy: 0.8953\n",
            "Epoch 64/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3008 - accuracy: 0.8860 - val_loss: 0.2189 - val_accuracy: 0.8953\n",
            "Epoch 65/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2929 - accuracy: 0.8941 - val_loss: 0.2177 - val_accuracy: 0.8953\n",
            "Epoch 66/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2824 - accuracy: 0.8941 - val_loss: 0.2175 - val_accuracy: 0.8953\n",
            "Epoch 67/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2697 - accuracy: 0.8905 - val_loss: 0.2137 - val_accuracy: 0.8953\n",
            "Epoch 68/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2770 - accuracy: 0.9005 - val_loss: 0.2162 - val_accuracy: 0.8917\n",
            "Epoch 69/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2801 - accuracy: 0.8914 - val_loss: 0.2102 - val_accuracy: 0.8989\n",
            "Epoch 70/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2733 - accuracy: 0.8977 - val_loss: 0.2103 - val_accuracy: 0.8953\n",
            "Epoch 71/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3079 - accuracy: 0.8760 - val_loss: 0.2075 - val_accuracy: 0.8953\n",
            "Epoch 72/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2797 - accuracy: 0.8914 - val_loss: 0.2056 - val_accuracy: 0.9025\n",
            "Epoch 73/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2766 - accuracy: 0.8968 - val_loss: 0.2104 - val_accuracy: 0.8953\n",
            "Epoch 74/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2794 - accuracy: 0.9050 - val_loss: 0.2116 - val_accuracy: 0.8953\n",
            "Epoch 75/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2786 - accuracy: 0.8959 - val_loss: 0.2040 - val_accuracy: 0.8989\n",
            "Epoch 76/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2572 - accuracy: 0.9059 - val_loss: 0.2031 - val_accuracy: 0.8953\n",
            "Epoch 77/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2555 - accuracy: 0.9086 - val_loss: 0.2050 - val_accuracy: 0.8953\n",
            "Epoch 78/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2629 - accuracy: 0.8986 - val_loss: 0.2010 - val_accuracy: 0.8953\n",
            "Epoch 79/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2519 - accuracy: 0.9086 - val_loss: 0.2053 - val_accuracy: 0.8953\n",
            "Epoch 80/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2639 - accuracy: 0.9014 - val_loss: 0.2003 - val_accuracy: 0.8953\n",
            "Epoch 81/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2650 - accuracy: 0.8968 - val_loss: 0.1958 - val_accuracy: 0.8989\n",
            "Epoch 82/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2618 - accuracy: 0.9014 - val_loss: 0.1991 - val_accuracy: 0.9061\n",
            "Epoch 83/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2565 - accuracy: 0.9005 - val_loss: 0.2062 - val_accuracy: 0.9061\n",
            "Epoch 84/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2594 - accuracy: 0.9113 - val_loss: 0.1990 - val_accuracy: 0.9061\n",
            "Epoch 85/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2559 - accuracy: 0.9050 - val_loss: 0.2025 - val_accuracy: 0.8989\n",
            "Epoch 86/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2674 - accuracy: 0.9068 - val_loss: 0.2015 - val_accuracy: 0.9061\n",
            "Epoch 87/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2811 - accuracy: 0.9014 - val_loss: 0.2010 - val_accuracy: 0.9025\n",
            "Epoch 88/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2630 - accuracy: 0.9041 - val_loss: 0.1991 - val_accuracy: 0.9025\n",
            "Epoch 89/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2418 - accuracy: 0.9158 - val_loss: 0.1948 - val_accuracy: 0.8989\n",
            "Epoch 90/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.9068 - val_loss: 0.1933 - val_accuracy: 0.8989\n",
            "Epoch 91/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2511 - accuracy: 0.9077 - val_loss: 0.1944 - val_accuracy: 0.9097\n",
            "Epoch 92/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2435 - accuracy: 0.9095 - val_loss: 0.2010 - val_accuracy: 0.9025\n",
            "Epoch 93/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2433 - accuracy: 0.9095 - val_loss: 0.1998 - val_accuracy: 0.9025\n",
            "Epoch 94/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2439 - accuracy: 0.9113 - val_loss: 0.1997 - val_accuracy: 0.8953\n",
            "Epoch 95/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2594 - accuracy: 0.9140 - val_loss: 0.1981 - val_accuracy: 0.8953\n",
            "Epoch 96/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2482 - accuracy: 0.9131 - val_loss: 0.1985 - val_accuracy: 0.8917\n",
            "Epoch 97/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2207 - accuracy: 0.9149 - val_loss: 0.1957 - val_accuracy: 0.9025\n",
            "Epoch 98/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2316 - accuracy: 0.9059 - val_loss: 0.1912 - val_accuracy: 0.9097\n",
            "Epoch 99/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2426 - accuracy: 0.9041 - val_loss: 0.1910 - val_accuracy: 0.9061\n",
            "Epoch 100/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2638 - accuracy: 0.8959 - val_loss: 0.1904 - val_accuracy: 0.9097\n",
            "Epoch 101/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2541 - accuracy: 0.9014 - val_loss: 0.1893 - val_accuracy: 0.9061\n",
            "Epoch 102/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2478 - accuracy: 0.9113 - val_loss: 0.1845 - val_accuracy: 0.9061\n",
            "Epoch 103/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2488 - accuracy: 0.9095 - val_loss: 0.1858 - val_accuracy: 0.9134\n",
            "Epoch 104/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2520 - accuracy: 0.9041 - val_loss: 0.1910 - val_accuracy: 0.8989\n",
            "Epoch 105/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2648 - accuracy: 0.8986 - val_loss: 0.1912 - val_accuracy: 0.9134\n",
            "Epoch 106/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2370 - accuracy: 0.9095 - val_loss: 0.1865 - val_accuracy: 0.9097\n",
            "Epoch 107/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2299 - accuracy: 0.9195 - val_loss: 0.1771 - val_accuracy: 0.9170\n",
            "Epoch 108/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2466 - accuracy: 0.9068 - val_loss: 0.1749 - val_accuracy: 0.9242\n",
            "Epoch 109/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2220 - accuracy: 0.9167 - val_loss: 0.1835 - val_accuracy: 0.9061\n",
            "Epoch 110/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2510 - accuracy: 0.9032 - val_loss: 0.1835 - val_accuracy: 0.9278\n",
            "Epoch 111/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.9014 - val_loss: 0.1826 - val_accuracy: 0.9170\n",
            "Epoch 112/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2269 - accuracy: 0.9113 - val_loss: 0.1827 - val_accuracy: 0.9242\n",
            "Epoch 113/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2366 - accuracy: 0.9113 - val_loss: 0.1783 - val_accuracy: 0.9314\n",
            "Epoch 114/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.9059 - val_loss: 0.1855 - val_accuracy: 0.9242\n",
            "Epoch 115/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2208 - accuracy: 0.9149 - val_loss: 0.1787 - val_accuracy: 0.9206\n",
            "Epoch 116/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2316 - accuracy: 0.9095 - val_loss: 0.1782 - val_accuracy: 0.9206\n",
            "Epoch 117/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2414 - accuracy: 0.8977 - val_loss: 0.1786 - val_accuracy: 0.9097\n",
            "Epoch 118/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2171 - accuracy: 0.9167 - val_loss: 0.1768 - val_accuracy: 0.9242\n",
            "Epoch 119/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2438 - accuracy: 0.9095 - val_loss: 0.1756 - val_accuracy: 0.9206\n",
            "Epoch 120/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2293 - accuracy: 0.9086 - val_loss: 0.1722 - val_accuracy: 0.9134\n",
            "Epoch 121/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2164 - accuracy: 0.9176 - val_loss: 0.1719 - val_accuracy: 0.9242\n",
            "Epoch 122/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2210 - accuracy: 0.9140 - val_loss: 0.1738 - val_accuracy: 0.9170\n",
            "Epoch 123/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2317 - accuracy: 0.9140 - val_loss: 0.1745 - val_accuracy: 0.9170\n",
            "Epoch 124/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2310 - accuracy: 0.9140 - val_loss: 0.1716 - val_accuracy: 0.9206\n",
            "Epoch 125/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2417 - accuracy: 0.9158 - val_loss: 0.1748 - val_accuracy: 0.9170\n",
            "Epoch 126/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2272 - accuracy: 0.9149 - val_loss: 0.1781 - val_accuracy: 0.9097\n",
            "Epoch 127/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2527 - accuracy: 0.9068 - val_loss: 0.1771 - val_accuracy: 0.9170\n",
            "Epoch 128/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2243 - accuracy: 0.9204 - val_loss: 0.1752 - val_accuracy: 0.9170\n",
            "Epoch 129/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2237 - accuracy: 0.9104 - val_loss: 0.1728 - val_accuracy: 0.9170\n",
            "Epoch 130/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2203 - accuracy: 0.9158 - val_loss: 0.1713 - val_accuracy: 0.9242\n",
            "Epoch 131/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2418 - accuracy: 0.9032 - val_loss: 0.1777 - val_accuracy: 0.9170\n",
            "Epoch 132/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2645 - accuracy: 0.9032 - val_loss: 0.1795 - val_accuracy: 0.9206\n",
            "Epoch 133/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2306 - accuracy: 0.9113 - val_loss: 0.1751 - val_accuracy: 0.9170\n",
            "Epoch 134/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2273 - accuracy: 0.9059 - val_loss: 0.1676 - val_accuracy: 0.9314\n",
            "Epoch 135/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2355 - accuracy: 0.9077 - val_loss: 0.1711 - val_accuracy: 0.9314\n",
            "Epoch 136/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2414 - accuracy: 0.9086 - val_loss: 0.1725 - val_accuracy: 0.9206\n",
            "Epoch 137/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2236 - accuracy: 0.9068 - val_loss: 0.1709 - val_accuracy: 0.9242\n",
            "Epoch 138/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2514 - accuracy: 0.9086 - val_loss: 0.1782 - val_accuracy: 0.9242\n",
            "Epoch 139/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2129 - accuracy: 0.9176 - val_loss: 0.1758 - val_accuracy: 0.9278\n",
            "Epoch 140/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2465 - accuracy: 0.9041 - val_loss: 0.1733 - val_accuracy: 0.9170\n",
            "Epoch 141/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2306 - accuracy: 0.9131 - val_loss: 0.1720 - val_accuracy: 0.9242\n",
            "Epoch 142/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2050 - accuracy: 0.9204 - val_loss: 0.1645 - val_accuracy: 0.9350\n",
            "Epoch 143/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2241 - accuracy: 0.9158 - val_loss: 0.1654 - val_accuracy: 0.9278\n",
            "Epoch 144/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2360 - accuracy: 0.9041 - val_loss: 0.1652 - val_accuracy: 0.9278\n",
            "Epoch 145/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2189 - accuracy: 0.9158 - val_loss: 0.1634 - val_accuracy: 0.9350\n",
            "Epoch 146/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1959 - accuracy: 0.9267 - val_loss: 0.1636 - val_accuracy: 0.9350\n",
            "Epoch 147/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1950 - accuracy: 0.9213 - val_loss: 0.1655 - val_accuracy: 0.9350\n",
            "Epoch 148/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2253 - accuracy: 0.9149 - val_loss: 0.1643 - val_accuracy: 0.9350\n",
            "Epoch 149/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1911 - accuracy: 0.9140 - val_loss: 0.1637 - val_accuracy: 0.9314\n",
            "Epoch 150/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2010 - accuracy: 0.9195 - val_loss: 0.1618 - val_accuracy: 0.9350\n",
            "Epoch 151/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2047 - accuracy: 0.9195 - val_loss: 0.1606 - val_accuracy: 0.9350\n",
            "Epoch 152/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2281 - accuracy: 0.9095 - val_loss: 0.1634 - val_accuracy: 0.9386\n",
            "Epoch 153/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1940 - accuracy: 0.9231 - val_loss: 0.1696 - val_accuracy: 0.9278\n",
            "Epoch 154/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2247 - accuracy: 0.9167 - val_loss: 0.1746 - val_accuracy: 0.9242\n",
            "Epoch 155/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2230 - accuracy: 0.9131 - val_loss: 0.1674 - val_accuracy: 0.9314\n",
            "Epoch 156/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2187 - accuracy: 0.9195 - val_loss: 0.1595 - val_accuracy: 0.9458\n",
            "Epoch 157/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2125 - accuracy: 0.9131 - val_loss: 0.1621 - val_accuracy: 0.9314\n",
            "Epoch 158/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1914 - accuracy: 0.9249 - val_loss: 0.1647 - val_accuracy: 0.9386\n",
            "Epoch 159/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2028 - accuracy: 0.9176 - val_loss: 0.1605 - val_accuracy: 0.9350\n",
            "Epoch 160/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2073 - accuracy: 0.9131 - val_loss: 0.1624 - val_accuracy: 0.9278\n",
            "Epoch 161/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2320 - accuracy: 0.9104 - val_loss: 0.1657 - val_accuracy: 0.9278\n",
            "Epoch 162/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2111 - accuracy: 0.9176 - val_loss: 0.1651 - val_accuracy: 0.9350\n",
            "Epoch 163/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1913 - accuracy: 0.9285 - val_loss: 0.1625 - val_accuracy: 0.9314\n",
            "Epoch 164/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9204 - val_loss: 0.1580 - val_accuracy: 0.9314\n",
            "Epoch 165/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2105 - accuracy: 0.9240 - val_loss: 0.1656 - val_accuracy: 0.9314\n",
            "Epoch 166/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2073 - accuracy: 0.9231 - val_loss: 0.1625 - val_accuracy: 0.9278\n",
            "Epoch 167/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2153 - accuracy: 0.9222 - val_loss: 0.1577 - val_accuracy: 0.9314\n",
            "Epoch 168/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2239 - accuracy: 0.9131 - val_loss: 0.1578 - val_accuracy: 0.9314\n",
            "Epoch 169/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2072 - accuracy: 0.9240 - val_loss: 0.1545 - val_accuracy: 0.9350\n",
            "Epoch 170/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1989 - accuracy: 0.9140 - val_loss: 0.1567 - val_accuracy: 0.9386\n",
            "Epoch 171/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2030 - accuracy: 0.9240 - val_loss: 0.1594 - val_accuracy: 0.9350\n",
            "Epoch 172/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2041 - accuracy: 0.9176 - val_loss: 0.1595 - val_accuracy: 0.9314\n",
            "Epoch 173/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1859 - accuracy: 0.9312 - val_loss: 0.1613 - val_accuracy: 0.9350\n",
            "Epoch 174/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2378 - accuracy: 0.9104 - val_loss: 0.1572 - val_accuracy: 0.9386\n",
            "Epoch 175/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1934 - accuracy: 0.9213 - val_loss: 0.1534 - val_accuracy: 0.9495\n",
            "Epoch 176/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2022 - accuracy: 0.9231 - val_loss: 0.1537 - val_accuracy: 0.9386\n",
            "Epoch 177/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2268 - accuracy: 0.9113 - val_loss: 0.1627 - val_accuracy: 0.9350\n",
            "Epoch 178/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9249 - val_loss: 0.1629 - val_accuracy: 0.9350\n",
            "Epoch 179/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1931 - accuracy: 0.9231 - val_loss: 0.1577 - val_accuracy: 0.9350\n",
            "Epoch 180/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2150 - accuracy: 0.9158 - val_loss: 0.1571 - val_accuracy: 0.9495\n",
            "Epoch 181/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2032 - accuracy: 0.9186 - val_loss: 0.1532 - val_accuracy: 0.9386\n",
            "Epoch 182/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2081 - accuracy: 0.9176 - val_loss: 0.1596 - val_accuracy: 0.9350\n",
            "Epoch 183/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1880 - accuracy: 0.9330 - val_loss: 0.1630 - val_accuracy: 0.9350\n",
            "Epoch 184/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2023 - accuracy: 0.9258 - val_loss: 0.1579 - val_accuracy: 0.9422\n",
            "Epoch 185/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.1979 - accuracy: 0.9213 - val_loss: 0.1573 - val_accuracy: 0.9422\n",
            "Epoch 186/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1984 - accuracy: 0.9258 - val_loss: 0.1580 - val_accuracy: 0.9422\n",
            "Epoch 187/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1925 - accuracy: 0.9276 - val_loss: 0.1627 - val_accuracy: 0.9350\n",
            "Epoch 188/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1989 - accuracy: 0.9167 - val_loss: 0.1626 - val_accuracy: 0.9386\n",
            "Epoch 189/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1699 - accuracy: 0.9285 - val_loss: 0.1600 - val_accuracy: 0.9458\n",
            "Epoch 190/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.9258 - val_loss: 0.1576 - val_accuracy: 0.9386\n",
            "Epoch 191/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1921 - accuracy: 0.9294 - val_loss: 0.1618 - val_accuracy: 0.9278\n",
            "Epoch 192/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1744 - accuracy: 0.9357 - val_loss: 0.1618 - val_accuracy: 0.9314\n",
            "Epoch 193/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2050 - accuracy: 0.9204 - val_loss: 0.1577 - val_accuracy: 0.9350\n",
            "Epoch 194/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2074 - accuracy: 0.9249 - val_loss: 0.1544 - val_accuracy: 0.9458\n",
            "Epoch 195/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1867 - accuracy: 0.9312 - val_loss: 0.1580 - val_accuracy: 0.9422\n",
            "Epoch 196/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1931 - accuracy: 0.9222 - val_loss: 0.1570 - val_accuracy: 0.9458\n",
            "Epoch 197/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1859 - accuracy: 0.9149 - val_loss: 0.1570 - val_accuracy: 0.9422\n",
            "Epoch 198/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1995 - accuracy: 0.9204 - val_loss: 0.1539 - val_accuracy: 0.9422\n",
            "Epoch 199/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1961 - accuracy: 0.9294 - val_loss: 0.1490 - val_accuracy: 0.9386\n",
            "Epoch 200/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2023 - accuracy: 0.9249 - val_loss: 0.1530 - val_accuracy: 0.9350\n",
            "Epoch 201/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2108 - accuracy: 0.9222 - val_loss: 0.1534 - val_accuracy: 0.9350\n",
            "Epoch 202/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2101 - accuracy: 0.9195 - val_loss: 0.1572 - val_accuracy: 0.9350\n",
            "Epoch 203/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1741 - accuracy: 0.9294 - val_loss: 0.1522 - val_accuracy: 0.9350\n",
            "Epoch 204/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1701 - accuracy: 0.9276 - val_loss: 0.1525 - val_accuracy: 0.9350\n",
            "Epoch 205/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2052 - accuracy: 0.9222 - val_loss: 0.1498 - val_accuracy: 0.9531\n",
            "Epoch 206/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2095 - accuracy: 0.9222 - val_loss: 0.1489 - val_accuracy: 0.9350\n",
            "Epoch 207/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1972 - accuracy: 0.9240 - val_loss: 0.1553 - val_accuracy: 0.9422\n",
            "Epoch 208/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9158 - val_loss: 0.1542 - val_accuracy: 0.9386\n",
            "Epoch 209/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1949 - accuracy: 0.9258 - val_loss: 0.1506 - val_accuracy: 0.9350\n",
            "Epoch 210/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1840 - accuracy: 0.9240 - val_loss: 0.1500 - val_accuracy: 0.9386\n",
            "Epoch 211/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1865 - accuracy: 0.9276 - val_loss: 0.1537 - val_accuracy: 0.9386\n",
            "Epoch 212/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1643 - accuracy: 0.9357 - val_loss: 0.1535 - val_accuracy: 0.9386\n",
            "Epoch 213/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1881 - accuracy: 0.9321 - val_loss: 0.1475 - val_accuracy: 0.9422\n",
            "Epoch 214/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2039 - accuracy: 0.9222 - val_loss: 0.1474 - val_accuracy: 0.9314\n",
            "Epoch 215/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1888 - accuracy: 0.9258 - val_loss: 0.1420 - val_accuracy: 0.9422\n",
            "Epoch 216/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2328 - accuracy: 0.9176 - val_loss: 0.1404 - val_accuracy: 0.9458\n",
            "Epoch 217/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2017 - accuracy: 0.9258 - val_loss: 0.1365 - val_accuracy: 0.9495\n",
            "Epoch 218/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2086 - accuracy: 0.9176 - val_loss: 0.1423 - val_accuracy: 0.9422\n",
            "Epoch 219/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1799 - accuracy: 0.9339 - val_loss: 0.1420 - val_accuracy: 0.9422\n",
            "Epoch 220/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1606 - accuracy: 0.9385 - val_loss: 0.1441 - val_accuracy: 0.9386\n",
            "Epoch 221/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1944 - accuracy: 0.9294 - val_loss: 0.1471 - val_accuracy: 0.9386\n",
            "Epoch 222/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1886 - accuracy: 0.9285 - val_loss: 0.1459 - val_accuracy: 0.9386\n",
            "Epoch 223/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1664 - accuracy: 0.9321 - val_loss: 0.1478 - val_accuracy: 0.9386\n",
            "Epoch 224/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1829 - accuracy: 0.9140 - val_loss: 0.1454 - val_accuracy: 0.9386\n",
            "Epoch 225/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1752 - accuracy: 0.9294 - val_loss: 0.1385 - val_accuracy: 0.9495\n",
            "Epoch 226/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1703 - accuracy: 0.9312 - val_loss: 0.1396 - val_accuracy: 0.9495\n",
            "Epoch 227/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2077 - accuracy: 0.9186 - val_loss: 0.1418 - val_accuracy: 0.9422\n",
            "Epoch 228/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1834 - accuracy: 0.9213 - val_loss: 0.1386 - val_accuracy: 0.9422\n",
            "Epoch 229/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1760 - accuracy: 0.9321 - val_loss: 0.1421 - val_accuracy: 0.9422\n",
            "Epoch 230/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1972 - accuracy: 0.9258 - val_loss: 0.1440 - val_accuracy: 0.9422\n",
            "Epoch 231/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1995 - accuracy: 0.9176 - val_loss: 0.1405 - val_accuracy: 0.9422\n",
            "Epoch 232/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1668 - accuracy: 0.9303 - val_loss: 0.1405 - val_accuracy: 0.9386\n",
            "Epoch 233/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1839 - accuracy: 0.9285 - val_loss: 0.1397 - val_accuracy: 0.9458\n",
            "Epoch 234/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1687 - accuracy: 0.9403 - val_loss: 0.1410 - val_accuracy: 0.9422\n",
            "Epoch 235/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2145 - accuracy: 0.9176 - val_loss: 0.1412 - val_accuracy: 0.9495\n",
            "Epoch 236/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1745 - accuracy: 0.9330 - val_loss: 0.1378 - val_accuracy: 0.9495\n",
            "Epoch 237/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2020 - accuracy: 0.9213 - val_loss: 0.1356 - val_accuracy: 0.9531\n",
            "Epoch 238/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1874 - accuracy: 0.9131 - val_loss: 0.1383 - val_accuracy: 0.9458\n",
            "Epoch 239/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1600 - accuracy: 0.9330 - val_loss: 0.1377 - val_accuracy: 0.9458\n",
            "Epoch 240/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2007 - accuracy: 0.9240 - val_loss: 0.1406 - val_accuracy: 0.9567\n",
            "Epoch 241/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2028 - accuracy: 0.9267 - val_loss: 0.1396 - val_accuracy: 0.9458\n",
            "Epoch 242/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1902 - accuracy: 0.9195 - val_loss: 0.1431 - val_accuracy: 0.9458\n",
            "Epoch 243/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1984 - accuracy: 0.9240 - val_loss: 0.1427 - val_accuracy: 0.9422\n",
            "Epoch 244/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1885 - accuracy: 0.9267 - val_loss: 0.1465 - val_accuracy: 0.9422\n",
            "Epoch 245/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.1777 - accuracy: 0.9367 - val_loss: 0.1422 - val_accuracy: 0.9495\n",
            "Epoch 246/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1720 - accuracy: 0.9285 - val_loss: 0.1387 - val_accuracy: 0.9531\n",
            "Epoch 247/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1790 - accuracy: 0.9294 - val_loss: 0.1451 - val_accuracy: 0.9458\n",
            "Epoch 248/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.9348 - val_loss: 0.1440 - val_accuracy: 0.9458\n",
            "Epoch 249/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1911 - accuracy: 0.9231 - val_loss: 0.1396 - val_accuracy: 0.9531\n",
            "Epoch 250/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1820 - accuracy: 0.9367 - val_loss: 0.1394 - val_accuracy: 0.9495\n",
            "Epoch 251/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1708 - accuracy: 0.9294 - val_loss: 0.1375 - val_accuracy: 0.9531\n",
            "Epoch 252/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1710 - accuracy: 0.9412 - val_loss: 0.1365 - val_accuracy: 0.9531\n",
            "Epoch 253/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1795 - accuracy: 0.9258 - val_loss: 0.1374 - val_accuracy: 0.9495\n",
            "Epoch 254/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1729 - accuracy: 0.9339 - val_loss: 0.1396 - val_accuracy: 0.9458\n",
            "Epoch 255/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1917 - accuracy: 0.9267 - val_loss: 0.1374 - val_accuracy: 0.9531\n",
            "Epoch 256/500\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.1921 - accuracy: 0.9249 - val_loss: 0.1396 - val_accuracy: 0.9386\n",
            "Epoch 257/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1625 - accuracy: 0.9339 - val_loss: 0.1376 - val_accuracy: 0.9458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We had specified 500 epochs but model's training stopped in 257th epoch because of no more improvement on val_loss.\n",
        ">\n",
        "According to the results of the training, the model has no overfitting and underfitting problem. The validation score in the last epoch is %94.58 while training accuracy is %93.39. That's a good result. \n",
        ">\n",
        "A figure below visualizes the results of each epoch"
      ],
      "metadata": {
        "id": "_CcKkFfWKBYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        ">\n",
        "Let see clearer on a figure."
      ],
      "metadata": {
        "id": "G9bPJZ-jJd3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(hist.history).plot()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Score\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "RNhXwrZ_YVhx",
        "outputId": "70e0fa8d-eb13-403a-9cb9-0a5bb330f30d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3iV5fnA8e9zRvYmISGBEHaAhCFhKlsUWhQXINqqqOCoWLV1LyraOuouiuBPgToQXEVRFGRvAkQ2YZMAIXuvM57fH28IAQIJIYcA5/5cFxfJO+8Twnu/z1Zaa4QQQrgvU0MHIIQQomFJIhBCCDcniUAIIdycJAIhhHBzkgiEEMLNWRo6gHMVGhqqY2JiGjoMIYS4pGzYsCFTax1W3b5LLhHExMSQmJjY0GEIIcQlRSl18Ez7pGpICCHcnMsSgVLqE6VUulJq6xn2ByqlflBK/a6U2qaUGuuqWIQQQpyZK0sE04GhZ9n/F2C71rozMAB4Uynl4cJ4hBBCVMNlbQRa62VKqZizHQL4K6UU4AdkA3ZXxSOEcA2bzUZqaiqlpaUNHYoAvLy8aNq0KVartdbnNGRj8X+AucARwB8YrbV2VnegUmo8MB4gOjr6ggUohKhZamoq/v7+xMTEYLzXiYaitSYrK4vU1FRatGhR6/MasrH4WiAJiAS6AP9RSgVUd6DWeqrWOkFrnRAWVm3vJyFEAyktLaVRo0aSBC4CSikaNWp0zqWzhkwEY4FvtWEPsB+IbcB4hBB1JEng4lGXf4uGTASHgMEASqlwoB2wz1U325VWwJu/7iKrsMxVtxBCiEuSK7uPfgmsBtoppVKVUvcope5XSt1fccgkoI9SagvwG/Ck1jrTVfHsSS/k/UV7yCoqd9UthBANxM/Pr6FDuKS5stfQmBr2HwGucdX9T2U2GcUlu0MW4hFCiKrcZmSxpSIROJySCIS4XGmtefzxx4mLiyM+Pp6vvvoKgKNHj9KvXz+6dOlCXFwcy5cvx+FwcNddd1Ue+/bbbzdw9A3nkptrqK4qSwTOanuoCiHqwT9+2Mb2I/n1es0OkQG8eF3HWh377bffkpSUxO+//05mZibdu3enX79+fPHFF1x77bU8++yzOBwOiouLSUpK4vDhw2zdakx+kJubW69xX0rcpkRwPBE4ZY1mIS5bK1asYMyYMZjNZsLDw+nfvz/r16+ne/fufPrpp0ycOJEtW7bg7+9Py5Yt2bdvHxMmTGD+/PkEBFTbe90tuE2JwCJtBEK4XG3f3C+0fv36sWzZMubNm8ddd93FY489xh133MHvv//OL7/8wpQpU5g9ezaffPJJQ4faINyuRCBtBEJcvvr27ctXX32Fw+EgIyODZcuW0aNHDw4ePEh4eDjjxo3j3nvvZePGjWRmZuJ0Orn55pt5+eWX2bhxY0OH32DcpkRwoo1AEoEQl6sbb7yR1atX07lzZ5RSvP7660RERDBjxgzeeOMNrFYrfn5+zJw5k8OHDzN27FicFe2G//rXvxo4+objdonAIW0EQlx2CgsLAWNU7RtvvMEbb7xx0v4777yTO++887Tz3LkUUJXbVA1ZTMZHdUgbgRBCnMRtEoFUDQkhRPXcLhFIY7EQQpzM/RKBtBEIIcRJ3CYRnJhiQkYWCyFEVW6TCGTSOSGEqJ7bJQJpIxBCiJO5TSKwSBuBEOI82e32hg7BJVy5MM0nSql0pdTWsxwzQCmVpJTappRa6qpYQEoEQlzubrjhBrp160bHjh2ZOnUqAPPnz+eKK66gc+fODB48GDAGn40dO5b4+Hg6derEN998A5y8uM3XX3/NXXfdBcBdd93F/fffT8+ePXniiSdYt24dvXv3pmvXrvTp04ddu3YB4HA4+Pvf/05cXBydOnXi/fffZ9GiRdxwww2V112wYAE33njjhfhxnBNXjiyeDvwHmFndTqVUEPABMFRrfUgp1diFsVQOKJM2AiFc6OenIG1L/V4zIh6GvVrjYZ988gkhISGUlJTQvXt3RowYwbhx41i2bBktWrQgOzsbgEmTJhEYGMiWLUacOTk5NV47NTWVVatWYTabyc/PZ/ny5VgsFhYuXMgzzzzDN998w9SpUzlw4ABJSUlYLBays7MJDg7mwQcfJCMjg7CwMD799FPuvvvu8/t5uIArVyhbppSKOcsht2EsXn+o4vh0V8UCUJEHpEQgxGXqvffe47vvvgMgJSWFqVOn0q9fP1q0aAFASEgIAAsXLmTWrFmV5wUHB9d47ZEjR2I2mwHIy8vjzjvvZPfu3SilsNlslde9//77sVgsJ93vz3/+M5999hljx45l9erVzJxZ7btxg2rIuYbaAlal1BLAH3hXa32m0sN4YDxAdHR0nW5WWSKQRCCE69Tizd0VlixZwsKFC1m9ejU+Pj4MGDCALl26sHPnzlpfQylV+XVpaelJ+3x9fSu/fv755xk4cCDfffcdBw4cYMCAAWe97tixY7nuuuvw8vJi5MiRlYniYtKQjcUWoBvwR+Ba4HmlVNvqDtRaT9VaJ2itE8LCwup0M1mYRojLV15eHsHBwfj4+LBz507WrFlDaWkpy5YtY//+/QCVVUNDhgxh8uTJlecerxoKDw9nx44dOJ3OypLFme4VFRUFwPTp0yu3DxkyhI8++qiyQfn4/SIjI4mMjOTll19m7Nix9feh61FDJoJU4BetdZHWOhNYBnR21c1kYRohLl9Dhw7FbrfTvn17nnrqKXr16kVYWBhTp07lpptuonPnzowePRqA5557jpycHOLi4ujcuTOLFy8G4NVXX2X48OH06dOHJk2anPFeTzzxBE8//TRdu3Y9qRfRvffeS3R0NJ06daJz58588cUXlftuv/12mjVrRvv27V30Ezg/SrvwDbmijeBHrXVcNfvaYzQmXwt4AOuAW7XWZ+xlBJCQkKATExPrFE/MU/N4eFBrHrumXZ3OF0KcbseOHRftA+5i8dBDD9G1a1fuueeeC3K/6v5NlFIbtNYJ1R3vssoqpdSXwAAgVCmVCrwIWAG01lO01juUUvOBzYAT+LimJHC+LCYlbQRCiAuqW7du+Pr68uabbzZ0KGfkyl5DY2pxzBvAGzUdV1/MJiUDyoQQF9SGDRsaOoQauc3IYjBKBLIwjRBCnMytEoFJqoaEEOI0bpUILCYlA8qEEOIUbpUIzCaTtBEIIcQp3CoRSBuBEEKczq0SgVnaCIRwe1VnGT3VgQMHiIs7bdjTZc/tEoEsVSmEECe7+GY/ciGLSSE1Q0K4zmvrXmNndu0nequN2JBYnuzx5Bn3P/XUUzRr1oy//OUvAEycOBGLxcLixYvJycnBZrPx8ssvM2LEiHO6b2lpKQ888ACJiYlYLBbeeustBg4cyLZt2xg7dizl5eU4nU6++eYbIiMjGTVqFKmpqTgcDp5//vnKKS0uBW6VCKREIMTlZ/To0TzyyCOViWD27Nn88ssvPPzwwwQEBJCZmUmvXr24/vrrT5phtCaTJ09GKcWWLVvYuXMn11xzDcnJyUyZMoW//vWv3H777ZSXl+NwOPjpp5+IjIxk3rx5gDEx3aXE7RKBTDonhOuc7c3dVbp27Up6ejpHjhwhIyOD4OBgIiIiePTRR1m2bBkmk4nDhw9z7NgxIiIian3dFStWMGHCBABiY2Np3rw5ycnJ9O7dm1deeYXU1FRuuukm2rRpQ3x8PH/729948sknGT58OH379nXVx3UJN2wjkEQgxOVm5MiRfP3113z11VeMHj2azz//nIyMDDZs2EBSUhLh4eGnrTFQV7fddhtz587F29ubP/zhDyxatIi2bduyceNG4uPjee6553jppZfq5V4XiluVCCwy15AQl6XRo0czbtw4MjMzWbp0KbNnz6Zx48ZYrVYWL17MwYMHz/maffv25fPPP2fQoEEkJydz6NAh2rVrx759+2jZsiUPP/wwhw4dYvPmzcTGxhISEsKf/vQngoKC+Pjjj13wKV3HrRKBlAiEuDx17NiRgoICoqKiaNKkCbfffjvXXXcd8fHxJCQkEBsbe87XfPDBB3nggQeIj4/HYrEwffp0PD09mT17Nv/973+xWq1ERETwzDPPsH79eh5//HFMJhNWq5UPP/zQBZ/SdVy6HoErnM96BCOnrMJiMvHl+F71HJUQ7kvWI7j4nOt6BNJGIIQQbs6tqoYsJhMlDkdDhyGEaGBbtmzhz3/+80nbPD09Wbt2bQNF1LBcuULZJ8BwIL26pSqrHNcdWI2xTOXXrooHZIoJIYQhPj6epKSkhg7jouHKqqHpwNCzHaCUMgOvAb+6MI5KMqBMCCFO57JEoLVeBmTXcNgE4Bsg3VVxVCUDyoQQ4nQN1lislIoCbgRq7GellBqvlEpUSiVmZGTU+Z4Wk8J5ifWSEkIIV2vIXkPvAE9qrWusq9FaT9VaJ2itE8LCwup8Q2kjEEKI0zVkr6EEYFbFJFChwB+UUnat9feuuqF0HxVC+Pn5UVhY2NBhXFQaLBForVsc/1opNR340ZVJAKSNQAhx8bDb7VgsF0cPfld2H/0SGACEKqVSgRcBK4DWeoqr7ns20kYghGul/fOflO2o3/UIPNvHEvHMM2fcX5/rERQWFjJixIhqz5s5cyb//ve/UUrRqVMn/vvf/3Ls2DHuv/9+9u3bB8CHH35IZGQkw4cPZ+vWrQD8+9//prCwkIkTJzJgwAC6dOnCihUrGDNmDG3btuXll1+mvLycRo0a8fnnnxMeHk5hYSETJkwgMTERpRQvvvgieXl5bN68mXfeeQeAadOmsX37dt5+++3z+vmCCxOB1nrMORx7l6viqMpsMkkbgRCXmfpcj8DLy4vvvvvutPO2b9/Oyy+/zKpVqwgNDSU72+gQ+fDDD9O/f3++++47HA4HhYWF5OTknPUe5eXlHJ8mJycnhzVr1qCU4uOPP+b111/nzTffZNKkSQQGBrJly5bK46xWK6+88gpvvPEGVquVTz/9lI8++uh8f3yAm40sNpuQNgIhXOhsb+6uUp/rEWiteeaZZ047b9GiRYwcOZLQ0FAAQkJCAFi0aBEzZ84EwGw2ExgYWGMiqLpyWWpqKqNHj+bo0aOUl5fTooVRY75w4UJmzZpVeVxwcDAAgwYN4scff6R9+/bYbDbi4+PP8adVPbdKBBaTCbtDBpQJcbk5vh5BWlraaesRWK1WYmJiarUeQV3Pq8piseCsMnD11PN9fX0rv54wYQKPPfYY119/PUuWLGHixIlnvfa9997LP//5T2JjYxk7duw5xXU2bjfpnBQIhLj8jB49mlmzZvH1118zcuRI8vLy6rQewZnOGzRoEHPmzCErKwugsmpo8ODBlVNOOxwO8vLyCA8PJz09naysLMrKyvjxxx/Per+oqCgAZsyYUbl9yJAhTJ48ufL746WMnj17kpKSwhdffMGYMbWufa+RWyUCi0lhlykmhLjsVLceQWJiIvHx8cycObPW6xGc6byOHTvy7LPP0r9/fzp37sxjjz0GwLvvvsvixYuJj4+nW7dubN++HavVygsvvECPHj0YMmTIWe89ceJERo4cSbdu3SqrnQCee+45cnJyiIuLo3PnzixevLhy36hRo7jyyisrq4vqg1utR/Da/J18vHwfu1/5Qz1HJYT7kvUILqzhw4fz6KOPMnjw4DMeI+sRnIVFRhYLIS5Rubm5tG3bFm9v77Mmgbpwq8Zis0mhNTidGpPp7N3IhBCXr0txPYKgoCCSk5Ndcm23SgSWioe/Q2tMSCIQor5orWvso38xuZzXI6hLdb9bVQ0dLwXIWAIh6o+XlxdZWVl1egCJ+qW1JisrCy8vr3M6zy1LBNJOIET9adq0KampqZzPFPGi/nh5edG0adNzOsetEoHZZBSApEQgRP2xWq2VI2LFpcmtqoYsUjUkhBCncZtEkFqQypb8X8BUKoPKhBCiCrdJBNuztvPLsf9gsuZIiUAIIapwm0QQ4mXMFqjMhZIIhBCiCpclAqXUJ0qpdKXU1jPsv10ptVkptUUptUop1dlVsQCEeFckAkuRJAIhhKjClSWC6cDQs+zfD/TXWscDk4CpLoyFRl6NAKNEIN1HhRDiBFeuULZMKRVzlv2rqny7Bji3jq/nyN/DHxNmlEWqhoQQoqqLpY3gHuDnM+1USo1XSiUqpRLrOmjFpEz4WQMlEQghxCkaPBEopQZiJIInz3SM1nqq1jpBa50QFhZW53v5WYIxmaWNQAghqmrQRKCU6gR8DIzQWme5+n7+1iCURdoIhBCiqgZLBEqpaOBb4M9aa9fMrXqKAI9glLkIhwwoE0KISi5rLFZKfQkMAEKVUqnAi4AVQGs9BXgBaAR8UDF9rf1Mq+fUlwCPoIo2AlfeRQghLi2u7DV01pWVtdb3Ave66v7VCfQIRpnKKbIVASEX8tZCCHHRavDG4gsp0MNY7DmvLLeBIxFCiIuHWyWCIE+jFJBbntPAkQghxMXDrRJBsKdRIsgvk0QghBDHuVUiCPI6XiJweU9VIYS4ZLhVIgjzNgajSSIQQogT3CoReFk8cNp9yJNEIIQQldwqEVjNJrQ9QBKBEEJU4VaJwMfDUpEIMhs6FCGEuGi4VSLw87Sg7f4U2KXXkBBCHOdWicDLalQNFTtycDgdDR2OEEJcFNwqESil8CAIjZMcGUsghBCAmyUCAC+TMagsvTi9gSMRQoiLg9slAh+zMagso7huK50JIcTlptaJQCnlrZRq58pgLgQ/i5EI0kukRCCEEFDLRKCUug5IAuZXfN9FKTXXlYG5yvEZSKVEIIQQhtqWCCYCPYBcAK11EtDibCcopT5RSqUrpbaeYb9SSr2nlNqjlNqslLriHOKuMz8PL0xOfzJKJBEIIQTUPhHYtNZ5p2yraeHf6cDQs+wfBrSp+DMe+LCWsZwXP08LOAKkRCCEEBVqmwi2KaVuA8xKqTZKqfeBVWc7QWu9DMg+yyEjgJnasAYIUko1qWU8debjaUbbAqTXkBBCVKhtIpgAdATKgC+APOCR87x3FJBS5fvUim2nUUqNV0olKqUSMzLO703e19OC3SZVQ0IIcVyNaxYrpczAPK31QOBZ14d0Oq31VGAqQEJCQk1VUmfl52HBXu5PVkkWdqcdi8llyzYLIcQlocYSgdbaATiVUoH1fO/DQLMq3zet2OZSvhXzDWk0WSUyC6kQQtT2dbgQ2KKUWgAUHd+otX74PO49F3hIKTUL6Ankaa2Pnsf1asXP04LTHgBARkkG4b7hrr6lEEJc1GqbCL6t+FNrSqkvgQFAqFIqFXgRsAJoracAPwF/APYAxcDYc7l+XRklAiMRSIOxEMIVtNaUbt2KV/v2KMvFX/1cqwi11jOUUh5A24pNu7TWthrOGVPDfg38pVZR1iNfT3NlIsgskXUJxOVDa41Sqt6va8/KoiQpCb9Bg066vj0jg9IdO/Dr1++CxnbsX69iDg4i9P77a32O1pqSTZtw5Ofj17//WWPJX7AAW+phfHp0x7tjx7Nf12Yj74cfsWdlUrRqFZbQMMKffoqczz4j84MPCbjuOiL/9c/KZOAsLiZ7xgwKlizBf9BgQsbeRdbHH1O0dBme7WMpTkzEWVSMV4cOBI64Hkd2Dnn/+x9Rb/4b5eWF2d8fZbXW+nPXVq0SgVJqADADOAAooJlS6s6KLqKXFGNNAl8UJikRiEuWs7gYLBZMHh4A2NLSOHTnXYTcfTdBI29B22yYPD3P6Zra6cRZWIg5IKBymyM3l4N33kn5nr2EPfIIofffZxxrt5PywIOUbt1K+HPPEfKn29Fakz/vJ0qSkgAwBwYSMvYubEeOcOTxJzAHBhL52qtYmxi9xO05ORwaezc47CgfH2wHD+Hbry+W4GB8evbEr2/f0x56xevXkz1jBphMeDRvTvmhFPz6XoVn+/Y4i4pw5BizCpcfOkRJUhIhd95J3vf/I3vmTGyHDgHg26c3nm3a4tO9K55t20OVpJA/7ycy3nnH+MZsJvD66zH5+p4Ug1dsO4rXJ1K4ciVmX0/KDxpNm9boaEoSN5D/ww8AeLZrR/4PP5D/ww94NG+OT5/eFK9ZS/n+/Xi0bEnG22+T8fbbAHi0akXunK/x7dkDs5eToqRNFP72W+U9Ux/+K/Zjxwi84QYa/+2xc/p3rQ1lvJjXcJBSG4DbtNa7Kr5vC3ypte5W7xHVICEhQScmJtb5/B1H8xn27nIiO73OkJgB/KPPP+oxOnEp0VpTtns3nq1aocxml92ndOdOHPn5+HTpgqp4cJ8q95tvsaUdJXTcOOwZGWS8/x8ceSfGcJobheAdF0fR2rU48wsoTkzEs3VromfMwOTrQ8q48RStWIHy9MTapAm2I0cIGDaUxk89hbJ6kDVtGspiwafbFWAyYfL2xisujrI9e3BkZVGcuIG8uXOxpabindCNgGHDKNu+lfxff0OXluLTPYGiVavxbNcOa2QkjpwcSpKS8GzXjrJdu/Dq0AGlSyjZsd94cFosOAsKMAcE4MjPxxwcjC4pQfn60Pyl+yhf8gUZm0yUH0jBK7YtzrIyPFq2onjdepxFRejSUszBwXh36gSmE31aSnftBLsDZ0kJzoKCyu0ezZtjO3IEbTu5osIaGYntyBG8u3Uj6JZbcOTmkvV//4czLxttc1b7b+E/9FrCx48i/ePZFK5cA1qD0w4mCzgcOIuKwGTCt00w9rQ0Qu8bh2+PTpiiOlB2rISCX+djsR0l6KF/kP/rQsoPHKB4/XpKd+3C4u9FRM8yfP70LAX7oWzZHLyaheJ//a3on/6OajkAVr6LbtSOoib34DyyA0dYd9L+MQmPcH+iJj2FV7+b6vR7qJTaoLVOqHZfLRPBZq11p5q2XQjnmwhSsovp+/pi2nb9mJaNwply9ZR6jE5cjLTTSdGq1fh0TyDns89x5ObSaPw40ib+g/x58/Dp3p2IF1/As3Vr43iHg8Kly/DuFI8lNJTy1FQcObl4x8fVeK+itevwiInBGt4YgNzvv+foU08Dxpto6IQJlO/bR3lqKiUbNhL+7LOUbtvG0WeeAcASEWE84LTG2sgTzB7gHYItJQVnYSGW8HAsjRrh0boV+fN+wrN1CyxhERStWEHoX/5CzhdfoMzgl9CBvN/WYfLxAYsFR3Y2oE+aD0B5eaJLyyq+Ufh2i8Pril4U/DSX8tRjKLPGv30QIc9/hFfzcHK+mkXB8g04stPAacdv4GBCH3mcnC++pGDet+jD2wiIsRPy0OOoiA4U//gJmQt24d1zMMGRB7CnH+XgV5k4S40HsNnHTJMHbsA/+zPQTrhtDkT3RKftoPC1UeTttVJeHgie/mAvgdxDKLOZsFGDcIR0oXDlakJHX0txio2Cb2fgERGIV2ApHF6P2ccbR1EJR9cFE9C9FZH/eBLl4Q0p68BWjF4wiSLLldj3bwJlBu0ArTFd9QD+ebNRhanQuCPcuwDmPwUbZ0LjjugRkymd/iimzC14BtqNcxu1gszdENgUxi2GFW/Bmg+g9RAIiIQ210BYLGz7Fla+C7YS434mi5FgADwDoKzA+DcKiobcQyd+f8PjKc70xbtsLaarn4IBT9Xp/0F9JIJPACfwWcWm2wGz1vruOkV0Hs43EWQXlXPFpAV0SfgOZc3iuxHf1WN04rxk7wd7KTRuf/o+WykUpRsPxqIM4z+p6fTez9rhQJnNaKcTtMaxbTFHnnqaon2FBPTtSv7qLWC3Y/L3x1lUROCNN5D/83x0cTEmH2+8OnTEu3M8Wf/3KZjNBI8eRf68H3DkFxI4bBDK6kHR2o14Ng8j9KaBqKadKJj3PexdTJlXPAVL12EK8MerbTvs2dnY09PxbNcO/yFXk/7qaycCVQqTpwUsHjgLi/BpFUhwnCf56RGYwlsSGleEx54ZxrGRXXH2eZzygwfwTJuLspdCj/Hkf/EB6YszsJdaaXz3TQSHbcfh3xG1eTpmZx6ljUeQtdMPbfIguHkmHkfnYSuygtbYSkwUpXni3ciGZ2w8VpWG1Z4Kzfug9y+nvNALi1cZZquGuJth6zdGLJ1vg82zjAe31RcSxhoPrSObjP2hbWDvIuNrr0DjQVmaaxwfEU/JURu5R6Pwu6IVfkemokxAs55QlAn5h6HbWNj8FSgTePpBzoGKn5cZQttCYBTsWXjyP3pwC8jZb3ztGQDd7oLBL8DS1yj/6S2sPg6U2WRcw1lRYogdDrd+DvuWwt7fwOINSZ9DXqrxgO73d1jyKngHQ0k2xI+C/UuhMB3Q0OM+IwGU5sHiV8AvHErzjW1ZeyG4OWTsMn5fHWUYNepAdG+44QPY8jXYiqHlACNp7FkId8yF7H3QbhgsfQ3yjxhfr3wP8lKg/xNw1aO1/d90mvpIBJ4YDbtXVWxaDnygtS6rc1R1dL6JoNTmIPb5+fTuvpwDZUtZfdvqeozOjTkdYDJDRjIcXGn8gttKIGMndLwRlMJ29Cj27GzY9DlWRwrmIX/HnpGBJW4gKj8Vpg2CsgLKOz9KzuJthPQJx0q28Z8zbbORJACHTZGd0x1L79txljtxFOTj1z6csp+nkL44i9A/jaB4bzbFietRtkKcdvAMgdIMBQoC/ziMko0baNLXhk+kFXt4X/K//YLyPE3OHh9wOPGLKsHi70PuTo3Zw4lfZCl5B71RJo1P43JKs604yk0oBdqpAI0yQXCbIkoKg3F4NsXioyg/eIjmr/4Vj6hI8uf/itMOPp3bYd44BdvRVFJXR+HXzE7jjumYgiMh9yDE3QJbv4ZeD0LkFfDrc1CYZvycQ9uCyQrp2wDQza+CfStQZoyHmb0EfBpB/EhY/7HxAPYLh4KjcNVj0O4PcHAFxPQ1fp6p6+G3l8DiZVz7aBJccQcc/R26/hkWTTIedvEjobwYds2DkJZw0zT49Xk4tMp4EDsdcP270HIgpKw1/s1ihxsP9//eAJ3HwMBnqvy+OGH1f4yk3/pqKM6Cb8cbD+VmvYyHZXAL4999729QcAz6Pwm+jYykk7HLKCkc3gjL34SrJxrxeviC1cu4h9awbwkERMGy16G8CFoNgqQvYNQM4827qt9nwXf3Qf+nYODTsPYj4wHdbpiRoAqOwvcPGA/z42/lRVnw2Y0w+EXjfnPuAlsRPJQIfo2NRLDmA1NZEwkAACAASURBVLCXQ7c7wT/i9P87DhsUpEFQs9P3Haf1SW0ZdVEficAXKK0YXHZ8tLGn1rr4vCKrg/NNBFpr2jz7M326bWFT4WesGrMKfw//eozwEqG18ZDI3gdzH4aIeGh/HaCNB0qz7icfn5qIIyOVchWDV4smOJwepL/5Jl4tmxPsvQTn3kRKGw3B+8h/MZkB3zCwl0FZPs4W15KVEkPmFz+C0/h9M1mceIeWU5TmhdVfYfFx4hVix6dVKOlLsrAVWjB7OPEMtRAQ34iga3uhwjtgS8vg0GtzKE8/UT+MyWQ8WACTh8ZZbvyH8YlwoiwmGj94B+Y1r7P35yb4RRTT9IYI43MHRhlvfIc3QKPWEBZL/oKF5O71I/KGSCyemqKt+7B06IPnqH8aD6UKDms4xybPxHlgHRGd07HcMQMSPzEekmsmGw+f/MMnHs6n8g2DttfCps+MB/dtcyC8I8y4DlLXGQ/RUTON5FpWaDxctYZWA8FRDt8/aDw4hrxkvIGmrDUeWCnrjAdc4/aQm2K85R7eAJ1vNd7sq3NozYlEkLYZonud2Pf7LDi6Ga6ZZPx7Ln4FutwO4R2MeMqLjDf3mn7XavMQczohMxnC2p3bQ6+ssOYYakNrOLIRmnQxfu51kbXXKCG1Gnj+8dSz+kgEa4CrtdaFFd/7Ab9qrfvUa6S1cL6JAKDbpAV0arefxJL3+fb6b2kT3KaeoquedlbfKFWVs7iYwsVLsGdmYm0ahV+/fif3mHA6KU7cQOmOHaefXFZgFD99Qo3iptUHHHaKVqyg7MABUCZMnp749OxJadIG7MdS8fAuxurjoPiYBa218Z+gsgJZGQ9IW4mxzWTF0yePslwT9mILJqsTrD44i403dLOXA0e5CZwKk4cJU2CQ8YanFFh9ceQXoh2KgOalBLRwoKO6k71ZU7JtJyHXdKN89xYcNiulR8vQNhvKy5MmzzxOwbI1lKekULZrF+awUKzhETjy83Hk5tLshfsxZW7CtPVLTBY7JbbmmK55Ec9OPdh/4wg8ffJodq0Tdc98o7oi7zBlmaVY0pZh3jnLeJu8aarxOVPWQVhbo1ph1m2QPB/uWWgkw5oeYvYyKMk5+U1v02ewe4Fx36sehUOrwSsYQlpAWb5RzdWotXHd9f8HrQcbVQpgVJFsnm1Ub3j41Ph7I0Rt1UciSNJad6lp24VQH4lg0JtLiAo/RpLjZT4Y/AF9m/atp+gMZfv2kf/TzziysylOTKQsObler19bVj8nPk2AVoOw55dQtGYdXsFleAY6KckLwl5Qjm9TJ6a2/Y2HYMFRQENqopEELJ5GUbsom6JMX0xenoS0yqY0xwoe/gRFHabM3pRiU1csEc3w8s+nODsAZ7mtol7UBGYrJg8TAR0C8R76J1SA8cDUDgeOnBwsoaGV8ToKCrAdOYKlcWMswcYCQlprcmfPoeT33ynbvZuyvXuJnvoRPgkVv88HVhpvkV1uB4vRI8dRWISJUpRJgU/Iuf3Q7GWQtcd4OxfiMnK2RFDbIW9FSqkrtNYbKy6YAFRT3r00BHlbKS8LAAscLaq/WS2cJSVkfvAhWdOmGV30/P3xbNGC0AcfgBq6JyqzGZ8ePfBs1YqS926nZNt2o0HK4gnbvoewtnhYMvEtW4QKa2Psi6ioSoi8wmiQy0w2GsQat4f07ZhadEflpULBLGjsg27hQPW6D3o9gPYzptaodmBNyjqjmmPwixDQBAqOoT18UZ5+xoNy+Vuw9FXwDcP7LwsJqvKwDTj9amf8vFWTAIDZ3x9zu5NXQ1VKETx6FMGjRwEnGoMrxVxp/Kl6HT9f4OS+37Vm8ZQkINxObRPBI8AcpdSRiu+bAKNdE5LrBfl4kF7giznQTFpRWp2v4ywvp2jlSqMf9sZNFMyfj7O4mKCRtxD28MNYwsLO/aJLX8fPsRy/WCB6l1HHnL0J1O9GnX7niga4hX8zelb4B8MdXxrVDIc3Go13y98EH3+jV4TTbjzUs/eh+v6tskfOWWtgm/Uw/hznH37ieIsn9BgHu3+Ffo+f+xv3eXJlf38h3NVZE4FSqjuQorVer5SKBe4DbsJYu3j/BYjPJYK8rexOL6Bxk8anJYKCJUtwFhXh26sXtqNplG7ZTMCwYZiDggDInDaN3Nlz8I6Po2jlqspBPyZfX/yHDSXoxhtPVFtUVV5k9LrwCzN6CJQVGg2LjnJI/tmoZ85IhrUfQqfRRp3zyneNc7vfC/uXgYcfjJxudG9L/sU4tuf9Rk8KgDZXGw1tqydDv7+Bb8Ubd9XeGvXBNxTGL67fawohGkxNJYKPgKsrvu4NPIOxSE0XjPUBbnFdaK4T6GMlt9hGS98mJ1UN5c+fz+FHH6toOD0hc+o0fHt0x1lcQsGCBXi0bEnRqtX4XnUVgSOux7N1a8whIZi8vE6cVJJjdKnzaWS8kf/0d+ONvvXVcGCF0XXPt7HRIHi8rzQYXQdHTDbOjehk9C6J6WskDGXUuQPQbqjx51RBzeCxHUYjqBBC1EJNicCstT6+3ORoYKrW+hvgG6VUkmtDc50gbw8KSu2E+0SwJdPoEmjPyeHIk0/h3aULYRMeomzPXkz+/libRJD+9tsUb9gIQOANN9Bk0ktnnvjJ6YSyPHi3s9H/OizW6KoYc5XRLW3Nh8bXcTcZb/X5R2DY68ZD38MXvCpq2c1WiK+SZ01e1d+vOhe4ukYIcWmrMREopSxaazswGGOR+dqee9EK8jEe4sGeYaQVp+HUTvJ/+AFdVkbExBfxatcO3z4nesa2+Oqrs1+w4JjRbTPxE2MoeuurjSTQ/ynYMtt4879lulGF0+/vRg8dpYyBO0II0cBqeph/CSxVSmVi9BJaDqCUao2xbvEl6Xgi8LeEYXfaySzOpHDO13jFx+N1Sq8VHHb46W9Gv+7Irsa23Qvhx0cgqpvRQJt3Yl4QrL7GqNCWA43Rif2fMKp1rN7Gfq/6XuhNCCHOz1kTgdb6FaXUbxi9hH7VJwYdmDDaCs5KKTUUeBcwAx9rrV89ZX80xvTWQRXHPKW1/umcP8U5CvQ2EoG3yWhkPbZ5LZbdu4mY+OLpB+9fChumw7Ft0OdhOLgKfv/SqMY5sAIiu0CvB4wqHd/GRkPqt+NODEE3mcHk7eqPJIQQdVZj9Y7Wek0122ocIVUxDcVkYAiQCqxXSs3VWm+vcthzwGyt9YdKqQ4Yq5bF1DL2OgvyMQYeeWojERSsXkUw4DdgwOkHb6uYlC51Pcz+s9FP3ysA7ppnjBStzoQN9R+0EEK4iCvr+XsAe7TW+wAq1iYeAVRNBJoTY5ACgSNcAEEVJQKT0+gSyqZtWKOjsUacMiGUvRx2/GDM0ZKRbMxNM3I6oE5MbCWEEJc4VyaCKCClyvepGIvUVzUR+FUpNQFjKOjVVEMpNZ6Khuro6OjqDjknx9sISss88TF74bv9ID5Dh598UM4B+PFRY8Ru5zHGrIV1nYhKCCEuYqdP6H5hjQGma62bYixk/1+l1Gkxaa2naq0TtNYJYXUZrXsKfy8rSkFeiZ2u+Y3wKCrHNyj3RH/+zXPgg97GVAt/+LfRC0iSgBDiMuXKEsFhoOoE200rtlV1DzAUQGu9WinlBYQCLl1M2GxSBHhZySuxEZ9W0XB87EuYMtfo0rl2CjTtYcxOebY5woUQ4jLgyhLBeqCNUqqFUsoDuBWYe8oxhzDGJ6CUag94ARkujKlSkI+V3OJymmVAiSdYAz0g6gpjsYyQVnDbLEkCQgi34LISgdbarpR6CPgFo2voJ1rrbUqpl4BErfVc4G/ANKXUoxgNx3fp2syLXQ+CvK1kF9sISyvhYCjENe+Fxx3fG4t5ePpLf38hhNtw6ejgijEBP52y7YUqX28Hrjz1vAshKtibVgdm43/gCIntFKlNO9MSpBQghHA7Dd1Y3GDaNPZnSO4vmEs0KaGKPYFNGjokIYRoEG6bCDoEO2hRYAxbOBym2G2yN3BEQgjRMC7ZiePOlS0tjZLfTyw+Hpu8ksIUY1CYs0Uz9uTubajQhBCiQblNIihJSuLwI4+etK0YX0qCGhHRtB27c3c3UGRCCNGw3CYR+F55JS3+978TG+bcwdZsMzPbTiI2ZAe/pSyi1F6Kl0WmjhBCuBe3SQTGwuj+xjdOB7CfnOjr2FKouC64DRrN3ry9dGwkC5cLIdyLezYW5x4EeynmxrHszywi1MOYv2hPzp4GDkwIIS4890wEGcYs2lFtuwCQmu6Lh8mD3TnSTiCEcD9umgh2AtCqfTf8PC2s2ZdDq6BW0mAshHBL7pkIMpPBLxyLbzA9WoSwem8WbYLbSNWQEMItuWciyNgJYcbaxL1bNmJfZhER3jGkl6STV3bJLsUshBB14p6JIHMPhLYFoG2E0ZPIh6YA0k4ghHA77pcI7OVQlgd+xrKU0SE+ACibMdeQtBMIIdyN+yWCkmzjb59gAKKCvDEpyMn3JtAzkF3ZuxowOCGEuPDcLxEUVyQC7xAAPCwmmgR6k5JdTGxwrCQCIYTbcWkiUEoNVUrtUkrtUUo9dYZjRimltiultimlvnBlPECVEkFI5aboEB8OZRfTLsSYc8julJlIhRDuw2WJQCllBiYDw4AOwBilVIdTjmkDPA1cqbXuCDziqngqnVIiAGjeyEgEsSGxlDnKOJh/0OVhCCHExcKVJYIewB6t9T6tdTkwCxhxyjHjgMla6xwArbVLF60Hqi0RNAvxIbOwnGi/1gDszN7p8jCEEOJi4cpEEAWkVPk+tWJbVW2BtkqplUqpNUqpoS6Mx3CGEgHA9CXFWJRV2gmEEG6loRuLLUAbYAAwBmMh+6BTD1JKjVdKJSqlEjMyMs7vjiXZYPECD5/KTbEVYwm+25SGN03ZmrX1/O4hhBCXEFcmgsNA1ZXgm1ZsqyoVmKu1tmmt9wPJGInhJFrrqVrrBK11QlhY2PlFVZxzUmkAoHVjf1Y8OZAbu0ZRkNuULRlbsDls53cfIYS4RLgyEawH2iilWiilPIBbgbmnHPM9RmkApVQoRlXRPhfGZJQIfEJO29w02IdhcRGUFERT6ihlR/YOl4YhhBAXC5clAq21HXgI+AXYAczWWm9TSr2klLq+4rBfgCyl1HZgMfC41jrLVTEBRhuBd3C1u/q2CcNiawnAnK3L+McP23A4tUvDEUKIhubSFcq01j8BP52y7YUqX2vgsYo/F0ZJNjRuX+0ubw8zY3t1YmZKI+ZsW05paguu6xzJFdHVJw4hhLgcNHRj8YVXnH1aG0FVT1zbjg7BnfH2P4hSTpYnZ17A4IQQ4sJzr0SgNZTkgE+jMx6ilOKebsOwU0TbZjks232evZSEEOIi516JoDQPtKPaxuKqekf2xqRMhDbeT1JKLnkl0oNICHH5cq9EUJJj/H2GxuLjAj0D6RTaiXy1BYdTs3qva9uvhRCiIblXIrCVGH9bfc5+HNC3aV8OFO7C17uIZbszWLj9GNuOyOplQojLj3slAvvxROBd46GDmg0CoGXMAX7dlsYDn29gwhebsDucroxQCCEuOPdKBLZS42+LZ42HtgpqRUxADNpnM5mF5dgcmn2ZRXy9IdXFQQohxIXlXonAfjwR1FwiUEpxdfOrSSnZijIXcWv3ZnRpFsS7v+2m1OZwcaBCCHHhuGkiqLlEAHBN82twagf3XFvAs39szxND23E0r5TP1sh6BUKIy4d7JoJatBEAxIbE0iqwFclFS/H3stKnVSh924Ty5q/JTJy7jd3HClwYrBBCXBjulQgq2wi8anW4UorhrYazKX0TKQXG0gqv3tyJIR3C+XztQYa8vYyfthx1VbRCCHFBuFcisJ9bIgD4Y4s/olDM2TUHgKggb94b05U1Tw+mXbg/by1IxnnKxHS7jxVgTKMkhBAXP/dMBNbaJ4Imfk0Y1mIYs3bNIrs0u3J7Iz9PHhzYij3phdzxyTre+203doeTzam5DHl7GfO3ptV39EII4RLulQiODyg7hxIBwH2d76PUXsr0rdNP2j68UyQ9YkLYn1nEWwuSGf/fDSzYfgyANftkNLIQ4tLg0mmoLzr2MkCB2eOcTmsZ2JLrWl3HZzs+Y1S7UTT1bwqA2aSYfX9vAD5cspfX5u9k/QGj1LDhUE69hi6EEK7iXiUCe4lRGlDqnE+d0HUCZmXmrQ1vVbv/7qtiCPP3pKDUTpCPlR1HCygqs59vxEII4XIuTQRKqaFKqV1KqT1KqafOctzNSimtlEpwZTzYy86pfaCqCN8IxnUax4KDC1h4cOFp+z0tZu6+sgUADw5ohcOp+T0l97zCFUKIC8FliUApZQYmA8OADsAYpVSHao7zB/4KrHVVLJVsJefcPlDV2LixtA9pz0urX6rsTlrV+H4t+XHCVYzuHo1S8OmqA8xen8Jbv+6SMQdCiIuWK0sEPYA9Wut9WutyYBYwoprjJgGvAaUujMVgLzuvRGA1WXmt32s4cXL/gvvJKzt5NlKzSREXFUigt5Wnh8WyYPsxnvhmM+8t2sM17yzjr7M2cdMHK/nPot2yFrIQ4qLhykQQBVR9bU6t2FZJKXUF0ExrPe9sF1JKjVdKJSqlEjMyzmPFMPv5lQgAWgS24D+D/sORoiNMXDXxjOMFxvdrxYy7e/Dp2O4kPnc1d/Rqztzfj5BdVM6/f03m9o/XMHnxHp74+ndsMqOpEKIBNVivIaWUCXgLuKumY7XWU4GpAAkJCXV/lbaV1rmNoKoujbvw165/5c0NbzIneQ6j2o2q9rj+bcMqv/7HiDieH94Bs0kxZ0MqL/5vG2v2GT2MOjUN4k+9mp93XEIIUReuLBEcBppV+b5pxbbj/IE4YIlS6gDQC5jr0gZje2mtZh6tjTs63kGfyD68vv51dufsrtU5FrMJpRSjEprxyyP9+P4vV9IjJoTXft7Jla8u4vX5O2W9AyHEBefKRLAeaKOUaqGU8gBuBeYe36m1ztNah2qtY7TWMcAa4HqtdaLLIrKX1nrm0ZqYlIlXrnoFP6sfExZNIKP43Kqsohv50KVZEM8P70BYgCfNQrz5YMlebp26hiO5JfUSoxBC1IbLEoHW2g48BPwC7ABma623KaVeUkpd76r7npW9tNYzj9ZGqHcokwdPJrs0mwcWPkBB+bn3DIpvGsiivw1g1vjevHtrF3YczefBzzeedlxmYRk5ReX1EbYQQpzEpeMItNY/aa3baq1baa1fqdj2gtZ6bjXHDnBpaQCMNoJ6KhEc1zG0I+8MeIe9uXt5cOGDpBbUfQWzEV2ieHhwG5JScpn7+xF6/nMhHV6Yz4rdmdw+bS0PfXl6gjiV1pppy/ZxNE9KFUKI2nGzkcVl9dZGUFWfqD78q9+/SM5J5qa5NzF372l5rtau7RgBwN9mJ6E1+HpaeOLr39l1rIC1+7LJL7Wd9fw96YW88tMOZqySxXOEELXjZomgpN5LBMcNjRnK/274H3GhcTy74lmmbp5ap+vEhPoSG+GPzaF5cEArxl4Zw5G8UpQCu1Ozak8mAOV2J9uP5FNmN5bNzCkqZ8PBbJIqRjPLpHdCiNpyr0Rgq982glNF+EYwdchUhrcczvub3mfiqokcLTz3hWvG9IimVZgvt/aIZkz3aHw9zIzpEY2/p4WlyRnsyyik5z8X8of3lvOfRXtIPlbA8PdXcPOHq5n7+xEAthzOk7mOhBC14mazj9Z/G8GpLCYLk66cRIBHALOTZ/Pz/p8ZGzeWq6KuIi40rlbXuLNPDHf2iQHAy2pmwWP9CfH1ILuwnAXb08kvtVNicxAfFci3Gw+zNDmDUptRMli+OxNfDzNF5Q4SD+bQv20YO9PymbUuhceuaUuAl9VVH10IcYlynxKB0wFOm0vaCE5lMVl4uufTzLtxHl3DuzI5aTJj5o3hvY3vYXOcvY6/OpFB3nhZzYzv35LsojLmbT7KLd2aMvbKGA7nlrA5NY/Hr21H95hgAEYmNMNiUsxcdYDpK/dzy4ermb7qAK/9vLPymml5pWw9nHemW55Vud3JC//byv7MojqdL4S4uLhPIqjD6mTnK9IvkilXT2HJqCXc3OZmpm2ZxpCvhzBz20zKHGXnfL0rooN55Oq2eFvN3HNVS67pGIGnxURjf09uvCKK4Z0iAejVMoQHB7ZmSXIGE3/YTmyEPzdf0ZTP1x5i8a505m9NY8jbS7n5w1XklZyemFbtzeRPH68l+QwT5a3dn8XM1QeZumzfOX8GIcTFR11qa+smJCToxMQ69DItyoI3WsKw16HnffUfWA201qw8spIZ22aw5ugaPM2eDI4ezIu9X8TH6nNO1yoss+PnadTqfb0hlVA/Dwa0a0xxuZ0Zqw4y9soYvKxmUrKLKSyz075JAEVldm6Zspo96QXYHJqWob7syyzitZvjGd09muW7M/htRzqdmwUyefFe9qQX4uNh5tO7utOzZaOT7j/px+3834r9BPlYWffM1XhY3Od9QohLlVJqg9a62pkb3CcR5B2GtzvAde9BtzvrP7BzsPboWhYcXMCc5Dm0DW7LuPhxDIweiNXk2vr77KJyHv5yE+2b+PP3a9sx7J3lNA7w5NWbOjHwzSVYTAqbw/h9ePG6Dny25iDp+WV8dV9vOkQGcCCziJzich7/ejPp+aXkl9r58PYrSIgJ4WBWEc1CfAgPOLcSl9aaX7cfo3erRtJ+IYQLSSIAyNoL718BN06FzqPrP7A6WHRoEa+ue5WjRUcJ9Q6lfUh7BkUP4sbWN2I2mV1+//d+281bC5K5snUj1u3PZvkTg5iydC9peaV8cPsVpOWXctMHq7BaFG0a+7NoZ3rluU8OjeXTlftJLzhRxeVhMfH9g1fSITKg1jH8d81Bnv9+Kzd1jeKt0V3q9fMJIU6QRACQthWmXAmjZkKH6pZFaBgOp4MVh1cwd+9cknOSOZB/gCDPIFoGtqRDI2Mdn5va3ESb4Db1fu+8Ehs3Tl7JvswibuwaxdvVPIg3HMxh9EerMZkUDw9qjd2p+W7TYT6/tydmk+KH349gc2hiI/x5+MtNDOkQzju3diW9oBSryYSHxcS8zUfJLCqje0wI3aKDMZmMpUK3H8nnxg9WYjWbKCq3M29C33NKIgAZBWVkFpbRvsnJ5+1My6eozEG35sF1/wGdh9ScYlKyS+jdqlHNBwtxAUgiAEjdAB8PgttmQ9tr6z+weqC1ZsHBBaw6sorknGR2Ze8ytqPp37Q/zfybEekXSd+mfYnyi6rharWzL6OQl37cznN/bE/rxv7VHrPhYDaB3tYz7j9u0o/bmb7qAA8OaMUnK/YT5ONB80Y+rNp7YnBbXFQAEQHelNkd7EkvRGv4fFxPbvpgFT1ahDDtjuonn/12YypLkzN47eZOeFlPlJZGTlnFxkO5vD+mK3+IbwLAoaxi/vj+cswm1WBtGGOmrmHjoRySXrgGbw/Xl+6EqMnZEoH7jCOwV8y9c54L07iSUoprYq7hmphrKrdll2bz3sb3WJ+2nqWpS7E5bZjWmbgn7h6uibmGSL9ItmZspcBWQP+m/fE6x8/XMsyP6WN7nPWYbs1DanWte/u24Jdtaby/aA+dmwayJ72Qw7klTLohjus7RfLLtjQ+WLKHncX5mE2KglI7X93Xi1ZhftzZJ4b3ftvN7MQUVuzOJKuojL9f046u0cGkZBfz7HdbKbE5KLM5+fBPV6CUYsPBbNYfyCHYx8pfvtjI6IRm+Hpa+GnLUYrLHTicmuW7MxjcPpzkYwW0CvPjo2V7mbf5KHGRgbx6czxawycr9zOgXWNaN/Y7p58dwKcr9/PlukPMe7gvVrORcLYezmN1xcjuNfuyGBjb+KRzVu7JZOqyfUy7I4FD2UXENPLFYpYGd9Fw3CgRVHQfvYgTQXVCvEKY2GciYJQYDhUcYurmqUzbMo1pW6addGyARwDDWw6nf9P+dA3vivcFGDNRVZNAb5Y/MZDsonKCfTxISs1lT3ohoxKMZSlGdW/GqO7NKj9Lmd1Z+XZ/Z+/mTF22lye+3kwjXw/MJsUtU1bj72WhpNyBxaS4+8oWfLJyP+v2Z9M9JoR3Fu4myMfKgsf6859Fe5i5+gAWk4keLUJ4c2Rn/vLFRv6XdARvq5nbPl7LE0Pb8cHivVjMim1H8hnVvSnr9ufw2vydrN2fzbQ7Eth+JJ9ft6dxb9+WjP5oNWOvbMEt3Zqe9DmdTm0ku2aBfLx8P4dzS1i5J5MB7YwH/icr9uPrYcapYfGudAbGGj26Pl15gNgIf2auPsjS5Ax+2ZbGI18l8edezZl4fccL9w91DorL7ZTZnAT7ejR0KMKF3KdqaMeP8NXtcN8yaNK5/gO7wPbk7GF//n5SC1KJ9Isk0DOQb5O/ZeGhhdicNqwmKy0DW+Jr9cXb6s3wlsPpFNoJH6sPx4qPUWwrJtwnnOiA6Ib+KJWmr9zPnoxCnhwai8P5/+2deXyU1dX4vzczmZnMTDLZ950EwhYChh0RZXNBqWJdKrZ1qb5VW9sKrb6162tbW39S11q12mpLtdbdurKDyB4IISwhCdn3fZlktuf+/pghJECoKDLK3O/nM588z32e3JwzdzLnueece67k6Y3l9Drc6IOCWDA2jtxkG/kPrGZxXhJGfRB/+6SCX10xdmAVdr/Lg1Hv3fwH4P43i3hlRw1RVgP1nf0YdEE4PRp/Xnoey/9dSHKkmZLGboz6INweyUu3TeWWF3bSYXdxxYRE3i6sw2zQ8cHds0mNMtPjcPN6QQ27Ktt5a08dwbpjWVZLJiXz8DUTaOzqZ+aDa7lxehrVbX0cbOji0evyuPvlPdS09xFq0g/MVlIiQ6hu6yNIwFt3zmJ8so33iup58P2DPPetfLLjTu2K+zRIKfnXjmoWjI0n8jN8mS//dyF7azr58IezP7cs/mRjSTN2p4eLx8X7WxS/oVxDAEKAOQpOM2f/y0pWRBZZEVlD2qYlTMPuslPQVMD2+u2UdZZhd9mp6Kzgvk33nbSf1UGdKwAAGsBJREFUtLA0ssOzmZE0g1ERo+h2dhMkgpgcPxl90Nn9eHx7ZsaQ859cnHPCPQvGxPHKzmo8muTmmRl8c/qxLT4Hxw4AfjR/FBUtdj4ubeGy3ATe3VtPhDmYeaNjuWpSEi9sqeS8tAh+OG8kS5/bxrVPbyXSYiDaauTtwjpiQ430OT388JU9vHjzFG57cedAvOOa/GTeKawnJFhwYU4sHxY3kLQqhOo2O5qU3DQjg93V7aw+0MiSp7aQYDPx+yXjue/1IjQJkRYD1W19JNhMuDwaf1xdwj0LRvKjV/bQ79L49X/28+LNUxBCsLW8lR1H2vje3GMJAzc+t43USDO3zc7kr5srSIsysyg3kZjQoSVUNpe2cu/rRRTWdPC7q3JP+r6vPdhImCmY/PQTXYC7Ktspb+mlpcdBSLCOm/+2gzsvzGL2oG1Yvwr89r0DNHb1M290rHLDnYQv9D9dCHEx8CigA/4ipXzwuOs/Am4F3EAzcLOU8oupn5xzmfd1jmMONjMraRazkmYNtGlSo7ilmNKOUhweB9Eh0YQaQinrKGNr/VYOtB1gddXqIf2EGcJIDk0mRB9Cflw+Bp0Ba7CVr4/8OsG6ofn+UkokkiDxxf+DXTkpmTf31LEoN4H7Lxs98PR/MiItBl68eQo17X3EhhnZWtbKotwE9Log7room2irkZtmZWAx6EiLMtPd72blrVN5p7COx9aW8vX8ZHLiw/jeS7uZ+ts19DjcPHR1LgvGxGMzB3NZbiIut0aU1cDm0lYeX3sYKeHisfGkRplJjfKuqyis7uDKiUnEhpk41NDDwYYucuLDeH7zEeaPiSPUpOep9WXUd/YTagrmO+en8PjaUtaXNHPhqFgeWV3C1vI2rpmcMtDfpsMthJr0aFLy0vZqAH733kFumpXOD+eNHDCKL22vArwLD793UTZmg479dV3kp0eiDxI89NEhnlpfRrg5mHX3zBniAup1uDnS6i0jsqeqg5YeB9uOtFHbUcTqH11Ar8NNUW3ngEvsy0qPw01JYzeahB0V7Wc8k+vjwy1MzojAqP/qJgV8Ya4hIYQOKAHmAzV4t668Xkq5f9A9FwLbpJR2IcR3gTlSylMm+X9m15BiWKSUlHWUUdtTiznYTJeji4/rPqa+t55uZzdFzUVIvJ+TcGM4YYYwxkSNYXz0eD6p+4SdjTsJM4TxwMwHyI3JpbanliRrEg6Pgx5XD2lhx57ai5qLsBltn8slVVDVzrhE22lnA7X1OrEYdSf9h61us2PQBxEXZqKpu5+fvrGPX10xlsTwEB7+6BAFVe3cNnsEF5ziSbjX4WZzaQsTUyNOeDI/nnWHmrjprzt48eYppEaamfP/1gPwf4vHct2UVM7//Tqy46w8cm0ek3+zGk3CH5bkcs3kFO55pZDXCrwbIOmDBPPHxLFs4SieWl/Gq7tquHxCIo9fP5ED9V1c8cTHzBsdx6r9jSydlkZbr5O3C+uwhQSTHm2hsLqDS8fH82FxI1dPSubBJePxaJK2XidVbXau/vMWAO6YM4LNpS1Ut/fR1utk2YKRFNV28mFxI8sXjqLX4eZbM9JPa0FhaVM36w81My0zinFJthOuuz0av3nvAG/tqSM5IoR/3DqVMFMwtR19PLOhDKdH4445WTy5rpS7LsoiOeLE2b7D7WFnRTs3/GUbABeOiiEr1so9C0adMIM8nr01HdS293GJLxvtZJQ0drPgjxv55eVjTpjRftnwS/qoEGI68Esp5ULf+X0AUsrfDXP/ROAJKeXMU/WrDMHZp6WvBZ3QUdRSxKrKVfS6eilsLqTJ3kSUKYpLMi5hc91mjnQeGfidEH0Ibs2NS3MxK2kW1426ji31W1h5YCUmnYmJsRMp7SglOiSaBEsC8ZZ4piZM5YLkC9AF6TjYdpCnC59GH6THEmzBZrQRa45FJ3RMSZhCpi3Tj+/I50dKyb7aLsYlhSGE4BvPbqWqzc6aey7AqNfx+JrDPLyqZCBAHhKsY3ySDbemUVDlnWG8U1iHW5M8el0ei/O86cS/e/8Az2wsZ+nUNP6+tRKLQcd/vn8+T64r5Z3COjya5KKcWMwGHTsq2rlpZjq3zMrgwfcP8vTGcialhrOvrgunWyMj2sKRll7iw0xIJI1dDn55+Ri2lrexvqQJh1vDYtDT4yt3vmRSMrogqG7rY+HYOEJNwSwcF88H+xqYlRVNvO2YkWjs6mf2H9bhcGtkxVr56AezCQoSuDwaT28oIznCzL92VLOlvJVZWdF8XNrCk9+YxGW5CVz22CYONXTj1iRWo/fvT06P4OXbpqMLOjZDLGnsZsmfPiHOZqK0qYcpGZFsP9IGMOQ9G47rntlCQWUHW/93LpEWA7ur2tlY0sKcUTFMSAkH4OXtVdz7ehELx8aRHRtKr9PNLy4fS4/DzQ9e3sPuqnZuOT+DBWPiaerqZ0ZW9Bn9HJ0O/jIEVwMXSylv9Z3fCEyVUt41zP1PAA1SygdOcu024DaA1NTU8yor1e5b/kZKSaO9kQhTBEadkV5XLx9VfES7o51YcywFjQUYdUbCjeGsPLCSdkc7AsGSkUtotjdT2lHKeXHn0dbfRkNvA3U9ddjddqzBVmxGG/W99YQZwgg1hNLv7qfd0Y5bO7a/wqTYSeTG5GLWmwkzhpEels70xOk4PU7eKH2Dqq4qUkJT+FrW1067lpM/6LS7cHq0gZlES4+DGQ+uxenWSI00M2NEFC/vqMYWEsz3Lsrihqlp3PS37RRUdrDrZ/MI9ZXnaOruZ9bv1+F0a1yWm8CvrxhLlNVIeXMPc1dsAGD9sjmkRVmG/H1Nk6xYVcI/tlVy6fgEKlp6+aSslXBzMIsnJPLClkpyk2388zvTaO91Mm/FBjQp+eAHs9l+pI09VR38a6fXRWULCR4oZmjQB+F0awPB9P11XbxXVE+kxcCv/7Of784ZwVPry/haXiJ2p4coq3HAnWU16vn55WO4amISE3+9istyE/j+3GxmPLiW+y7JoarNzkvbq7h2ciovba/ijjkj+LEvrqRpkmuf2cKOinYAsmOt/PHaPN7fV89ru2oZl2TjL9/K5+dv7aOsuYefXjpmyGLGPqeHCb/6CKdH438vzWH2yBgueXQTUsLUjEj+dft0AO59be/AuPS7PDjcGn+6YRJBQvA//9hFdqyV0uYeTHod/W4PK66ZwJUTh2ah1XX0seZgE9dPTjkhftHU3c9jaw7T0+9m+cU5JIV/9kzAL32wWAixFMgHLjjZdSnlM8Az4J0RnEXRFMMghCDeciwDwxJs4crsKwfOF2UuGji+ccyNbG/YzpioMcSaT+5Pdmtu1latZWfjTjodnVw+4nKWjl6Kzeh1Gbg0F93ObuwuO2uq1vBqyau8fPBl+j39A30kWhLpdffS6ejEEmyh19XLc0XP8ef5fybdls7zRc9T0VWBSW8i1BCKWW8mNyaXZ/c+S15sHrfn3n7a6zCGw+6y45ZuwgyfbqW0zTw07hJtNfLGHTPYVt7GxNRwNAmFNZ38YUku45O978m9l4ymoqV3wAgAxIaauHtuNgfqu3j4mgkDbrDMGCs3z8zA4facYAQAgoIEyxaOYtnCUQBUtvYy9+ENjE0M49szM7AY9dx5YRYWox6rUc/vrhpPj8PNiBgrI2KsXJQTy5t7apmQEs7KW6fS1uvkYEM3L35SQbvdyUf7G2jsGsWtL+ygrrMfs0HHiBgL98wfyXtF9bw5KAvr2vwUrs5PJi3STKzP1TQjK4pNh1vI8z2JXzAqhlFxodw9L5sYqxGQ/Gl9GW/sriUr1soNU9PYUdHOPfNH8tzmI0wf4XU/jUuy4XBpvLClgsaufl7eUY3TrXHdM1tYu2wOrxd4XWuHG3twejRCTXpWbqtiT3UHIcE6Fucl8srOGj4+3ML2ijZ2V3WgDxIDhi/BZuIXbxdzyThvZeBXvzuDbz63DV2QwKjXsezfewkJ1nPxuHg0zftV9ujqw/xrZzUfH27m8esnYdAH0e/yICX89t0DvFtUj0eTJIaHDBi6M43fXUNCiHnA48AFUsqmEzo6DuUaUgzGo3nodHayrX4b75a/S6QpkkWZi5iSMIWCxgKWbVhGv7ufRGsih9oPkWRNos/dR4+zB5fmQiIHjAZ4XVqhhlDCDGHEW+KZEj+FsVFj6XR2UtFZQb+nnzGRYyhuLWZ11Wra+9tJC0sjw5ZBTmQOKaEpvFD8AtsbtqMP0rMocxHL8pfhkR7KOsoIDgrmvSPv8f6R98m0ZTIuehzjoscxM2nmpzYag9ndtJvdTbu5Puf6M75u5L2ieuLCTJ+6TMeRll7iwoyYDUOfL4/GQxJtJlp6nKRHmylp7OHOC0ewfGEOBxu6aOjsZ0SMlbcL67hpZvoJffxjayX3v7mPnPhQ2u1Ott43d0iigNuj8eD7B9lR2U5hdcfAk/PGH19Ih92JxagfiAkUVnew+MnNzBkVw/pDzSxfOIqHPjxEZoyF8uZeoiwGRieEse1IK49cO5Hvv7x7IEvtstwEljz1yUAqMsCVE5N4Y3ctaVFm7r9sDN95cSdGfRCTUiN46bZpaJpECLA7PSx9bhvFtV3cOD2NdwrruHBULGsONmHUB1Hb0cdVE5O4aWYGd71UQE+/mza7k9tnj6C4rpPqNjvrls05ZYLEqfCXa0iPN1g8F6jFGyz+hpSyeNA9E4FX8bqQDn+afpUhUJwO1V3VPFLwCOWd5SwdvZQlI5cMXGvsbeSTuk84P/l8SjtKKWwqpNvZTberm47+Dqq6qyjtKB3Sn0AMZEhNjp9MsjWZqu4qyjrKaOv3+p/DDGHcMPoGOhwd/Lvk34ToQ+hx9gwE3AHmps6lua+Zg60HcWpO4i3x3DLuFlyaC6POSKYtE32QnsquShweB0nWJBKtiSRYEjDpTdR01/DQjodYW70WgJERI1kxZwWJ1kSKW4oRQpAbnUtNdw2bajchkWSHZ5MXm0ePq4eNNRuZEDOBDNvpBTi7nF10OjqJt8SfUC23y9lFiD5kSHtHfwe9rj4uWVFIn1Pj0esmkhxh4o5/7uJv3572qVdzN3T2s+CPG+jqd/P185J56OsnXwvU5/Qw/cE1dNhdLFswkrsuOrFGl5SSa572uo3MBh27fz6fbzy7jV2V7cwZFUNDZz8HG7qZkhHJK7dPZ0dFG3/dfIRfXD6WaKuRKb9ZTWuvk/QoMxWtdp7/dj7Pf1zBwnHxXJufwtTfrqbd7uL7c7P50fyRQ/52p93FT17bywfFDZiCg+h3eY3JI9fmUdVmZ8WqEgCiLAbiwkw0dvWz5p4LeH9fA/e9XsS735/F2MQTA+ufBr/VGhJCXAo8gjd99Hkp5W+EEL8Gdkop3xZCrAbGA0c39q2SUl5xqj6VIVCcTWq6a6jvrcccbCbTlolAsK9lH5nhmUSajuXdSylp7mvmcPthciJziArxpigWNRfxbNGz5ETmkBebh8PtICokitwYb06/S3Oxp2kPP9v8M2p7aj+VTDajjU5HJyadidsn3E6GLYNffPILnB4nAoHdbQfArDcPHB8l0hSJTuho7msGYGrCVMZHjyc1NJWU0BQKmgrY17IPu8tOdXc18ZZ4rh55NfPT5rOxZiP3bboPp+Yk0ZLI4qzFpISmkBKawhN7nmB7/XYSrYlcmnEpwUHBFLcWs6Fmg08WKznheRiDPWyt34pO6Dg/+XwWZy2my9FFVXcVlmAL4cZwpidOH1JLq6yjjP2t+8mPPp9NJd3MzI4mKdybjFDeWU6UKWrg/ZZSsmLVAf6yqZINP76Q2NCTu/q2lLVy/bNbmT8mjme/mc/GkmYeeHc/f79lKjFWI+sONZEWZT5pfa0n15VS3Wbn7nnZ/GXTEZYvHJqB9LM39/H3rZWsvHUqM4cJDh9u7MYUrGPuig14NMmu++dhCwlm1f5G2u1OZo+MITbURL/Lg8Wop63XyeTfrOZ/Lshk+cLP5h5SRecUii85To+T5r5mrMFW7C475Z3leKSH5NBkzHozdT111PbUUtdTR4O9gdTQVC5Ov5gEqze1sb6nnkcKHiHUEMrUhKl0Oboobi0mKzyL2cmzCdGHsLd5L68efpW6njqWT17OwbaDrNy/ktb+VjzSMyBLpi2TMEMYCZYE9rftp7LrWHJGXkweV2RdwWslr1HcOjC5J9IUyVXZV7Glbgv7W/cjkUSHRHNl1pXEW+LZ37qfbfXb0KTGgvQFuDQXH1Z8SEtfCwBBIghNagP9zUyaSZeji5L2koHd/I4mEhytzLuxZiMH2g4AkBuTywjbCAqaCqjsqiTcGMGdeXeQactkQuwEjLoT03n/vKGM7EQ36TF6BIJGeyNjo8d+JhfdYKpa7Ty7qZz7F40ekqrs0Tx0ObuIMB1ztf1pfSn1Hf3839f++37m/9xWRV5K+GlX6D2KMgQKhWJYpJTsb9tPs72ZCTEThnxRSSnZ0bBjYK3IkpFLBmIRLo+Lfa37KGou4ooRVxBu8gZyNamhSe2/rkx3a262N2wnzBDG2KixODUn9T31fFDxAS8dfIkIYwSzkmaRYE0gKzyL9468R5+7jwOtB6jqriLKFMXtubfT7epmdeVqmu3NpNvSyY/PZ2vdVgqaCgBvEsGiEYuYFDsJk97EW6Vv4dScFDYVUtNTM0QmndBx87ibyY/L50DbAdyam7SwNDbVbqK0o5TRkaPJCs/CrblxSzduzY1Ecl7seUyKm4Rbc9Nsb8bhcbC7eTeGIAM7G3fSbG+mrLOMht4GJsdPZl7qPF4//DpN9iZGR41mUeYiIk2RZIVnEWuOxSM9lHeW09HfQVJoEpVdlSRaEkkNS/3MCzeVIVAoFOcUHs07gxluAydNahxoO0BDTwPPFz/PvpZ9AzOO0OBQLAYLOZE5TEuYRrgxHI/0EG2K5j/l/+Gd8ncG+jkaEwo3hjMyYiRFLUX0Ha1kfBwh+hA8mgen5hzSbg22kmHLIMIUQU5kDu+Wv0ttTy0JlgRmJM5gU+0mmuzH8mT0QXo8mmdITOkoS0cv5SdTfnJ6b9ZRXZQhUCgUgYzD42Bd9Tpa+1q5MuvKU64tKWouwqk5ybRl4tbcVHdXMz5mPMFBwTg9TvrcfeiD9OiD9OiEDqfHyce1H7OrcRe6IB0jI7wB4omxE9GkRqI1cYhrSpMah9oOkRaWhjnYjEtzUd5RTrezm8Mdh2nsbcSgM5ASmkKEKYLa7lpSw1Kp760n05ZJXuxn28lPGQKFQqEIcE5lCFQZPoVCoQhwlCFQKBSKAEcZAoVCoQhwlCFQKBSKAEcZAoVCoQhwlCFQKBSKAEcZAoVCoQhwlCFQKBSKAOcrt6BMCNEMfNYtyqKBljMozpedQNI3kHSFwNI3kHSFL07fNCnlSTfd/soZgs+DEGLncCvrzkUCSd9A0hUCS99A0hX8o69yDSkUCkWAowyBQqFQBDiBZgie8bcAZ5lA0jeQdIXA0jeQdAU/6BtQMQKFQqFQnEigzQgUCoVCcRzKECgUCkWAEzCGQAhxsRDikBCiVAhxr7/lOdMIISqEEEVCiD1CiJ2+tkghxCohxGHfz4j/1s+XFSHE80KIJiHEvkFtJ9VPeHnMN9Z7hRCT/Cf56TOMrr8UQtT6xnePEOLSQdfu8+l6SAix0D9Sf3aEEClCiHVCiP1CiGIhxN2+9nNufE+hq3/HV0p5zr8AHVAGZAIGoBAY42+5zrCOFUD0cW1/AO71Hd8L/N7fcn4O/WYDk4B9/00/4FLgfUAA04Bt/pb/DOj6S2DZSe4d4/s8G4EM3+dc528dTlPfBGCS7zgUKPHpdc6N7yl09ev4BsqMYApQKqUsl1I6gZeBxX6W6WywGHjBd/wC8DU/yvK5kFJuBNqOax5Ov8XAi9LLViBcCJFwdiT9/Ayj63AsBl6WUjqklEeAUryf968MUsp6KWWB77gbOAAkcQ6O7yl0HY6zMr6BYgiSgOpB5zWc+s3/KiKBj4QQu4QQt/na4qSU9b7jBiDOP6J9YQyn37k63nf5XCHPD3LznVO6CiHSgYnANs7x8T1OV/Dj+AaKIQgEZkkpJwGXAHcKIWYPvii988xzNlf4XNcPeAoYAeQB9cDD/hXnzCOEsAKvAT+QUnYNvnauje9JdPXr+AaKIagFUgadJ/vazhmklLW+n03AG3inj41Hp8y+n03+k/ALYTj9zrnxllI2Sik9UkoNeJZj7oFzQlchRDDeL8aVUsrXfc3n5PieTFd/j2+gGIIdQLYQIkMIYQCuA972s0xnDCGERQgRevQYWADsw6vjt3y3fQt4yz8SfmEMp9/bwDd92SXTgM5BLoavJMf5wK/EO77g1fU6IYRRCJEBZAPbz7Z8nwchhACeAw5IKVcMunTOje9wuvp9fP0dRT9bL7yZBiV4o+4/9bc8Z1i3TLyZBYVA8VH9gChgDXAYWA1E+lvWz6HjS3inzC68ftJbhtMPbzbJk76xLgLy/S3/GdD17z5d9vq+HBIG3f9Tn66HgEv8Lf9n0HcWXrfPXmCP73XpuTi+p9DVr+OrSkwoFApFgBMoriGFQqFQDIMyBAqFQhHgKEOgUCgUAY4yBAqFQhHgKEOgUCgUAY4yBArFcQghPIOqQO45k9VqhRDpg6uKKhRfBvT+FkCh+BLSJ6XM87cQCsXZQs0IFIpPiW/Phz/49n3YLoTI8rWnCyHW+gqGrRFCpPra44QQbwghCn2vGb6udEKIZ3316D8SQoT4TSmFAmUIFIqTEXKca+jaQdc6pZTjgSeAR3xtjwMvSClzgZXAY772x4ANUsoJePcXKPa1ZwNPSinHAh3Aki9YH4XilKiVxQrFcQgheqSU1pO0VwAXSSnLfYXDGqSUUUKIFrwlAVy+9nopZbQQohlIllI6BvWRDqySUmb7zn8CBEspH/jiNVMoTo6aESgUp4cc5vh0cAw69qBidQo/owyBQnF6XDvo5xbf8Sd4K9oC3ABs8h2vAb4LIITQCSFsZ0tIheJ0UE8iCsWJhAgh9gw6/0BKeTSFNEIIsRfvU/31vrbvAX8VQiwHmoGbfO13A88IIW7B++T/XbxVRRWKLxUqRqBQfEp8MYJ8KWWLv2VRKM4kyjWkUCgUAY6aESgUCkWAo2YECoVCEeAoQ6BQKBQBjjIECoVCEeAoQ6BQKBQBjjIECoVCEeD8f1qTQTGIsxAkAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time to Touch Test Dataset"
      ],
      "metadata": {
        "id": "RzkjN_5K4tfl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets now evaluate the model on the test dataset."
      ],
      "metadata": {
        "id": "uOq_UdJyZ3X7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = dummies(test_data, test_data.drop(\"Car\", axis=1).columns)\n",
        "test_data = transforming_data(test_data)\n",
        "X_test = test_data.drop([\"Car\"], axis=1).values\n",
        "y_test = test_data[[\"Car\"]].values\n",
        "y_test = to_categorical(y_test, nb_class)"
      ],
      "metadata": {
        "id": "osIaooAy4tFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before evaluating the model and predict, we have made some preprocessing on the test dataset like we did for the train dataset. "
      ],
      "metadata": {
        "id": "sXvzGYPsZ0mF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(X_test, y_test, batch_size)\n",
        "\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "375TXQML2IqN",
        "outputId": "283ff804-652c-4e50-c52a-eeb1b50d1182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0901 - accuracy: 0.9566\n",
            "Loss: 0.09013073891401291\n",
            "Accuracy: 0.9566473960876465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result is good. Lets predict first 10 datas in X_test."
      ],
      "metadata": {
        "id": "q7r701a5aR5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = [\"unacc\", \"acc\", \"good\", \"vgood\"]"
      ],
      "metadata": {
        "id": "F0SyGEqtaqAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_prob = model.predict(X_test[:10])\n",
        "\n",
        "pred_class = np.argmax(pred_prob, axis=1)\n",
        "\n",
        "for i in range(10):\n",
        "  print(f\"Estimated class is {pred_class[i]} and it's label is\", class_labels[pred_class[i]])"
      ],
      "metadata": {
        "id": "Ur4sEPfADUPp",
        "outputId": "3b7dacc4-1191-4731-b478-eae36a498449",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated class is 0 and it's label is unacc\n",
            "Estimated class is 1 and it's label is acc\n",
            "Estimated class is 0 and it's label is unacc\n",
            "Estimated class is 0 and it's label is unacc\n",
            "Estimated class is 0 and it's label is unacc\n",
            "Estimated class is 0 and it's label is unacc\n",
            "Estimated class is 0 and it's label is unacc\n",
            "Estimated class is 0 and it's label is unacc\n",
            "Estimated class is 3 and it's label is vgood\n",
            "Estimated class is 0 and it's label is unacc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model has predicted classes of the first 10 data. We have printed the class results and their labels by using a for loop. Lets compare the result with original results."
      ],
      "metadata": {
        "id": "yd-1fTr7dj5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:10]"
      ],
      "metadata": {
        "id": "tWD3EFgwBjzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c9e43d-a808-4f38-fabc-6b0ae326e3df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model has correctly predicted all."
      ],
      "metadata": {
        "id": "v6nJs7w-dzha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, lets save the model and finish the process"
      ],
      "metadata": {
        "id": "IgH6VK1lPwjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"DNN_For_Car_Evaluation.h5\")"
      ],
      "metadata": {
        "id": "i6XW6-9TO2YO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}